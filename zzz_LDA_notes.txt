LDA hyperparameters
alpha:	doc-topic density
beta:	topic-word density
no. of topic terms ???
no. of iterations

Number of Topics: Kullback Leibler Divergence Score for optimization

Cleaning: e.g. punctuation, stopwords, normalization
dictionary.doc2bow

frequency filter
POS tag filter – remove IN, CD, MD?
batch wise: different batches, different LDA results – use intersection

-------------

best: chi2 20-30% 

PCA:
unter 1000 components schlechtere Ergebnisse, braucht zu viel RAM für vollen Datensatz

TruncatedSVD: 
nur machbar bis min_df word/char 30/60, 100/1000 components
deutlich schlechtere Ergebnisse für weniger components
ab 1000 gut!

chi2: machbar für min_df 20/20

Ergebnisse SS:		SVD 30/60	1kfeat		chi2 30/60 20%	8kfeat		chi2 20/20 20%	16kfeat		chi2 20/20 10%	8kfeat		30/60 voll

(r,p bzgl positiver Klasse)

itSGD 			r47,p56,acc70	(16s)		r73,p61,acc75	(38s)		r84,p54,acc69	(250s)		r80,p55,acc71	(93s)		r62,p67,acc77 	(81% c, 5% a, 75%hp, 8%hn) (690s)
itLogit			r60,p66,acc77	(400s)		r51,p74,acc78	(1200s)		r55,p70,acc77	(2900s)		r51,p75,acc78	(1200s)		r56,p72,acc78	(6000s)
itSVM			r75,p60,acc75	(1900s)		r75,p60,acc75	(130s)		r75,p58,acc73	(130s)		r74,p59,acc75	(97s)		r76,p60,acc75	(91%c, 25%a, 86%hp,  (720s)

supSGD: findet idR fast alle abstracts gut, also nur baseline!
supMLP:	etwas besser (60% abstracts), overfittet aber deutlich

supSGD			r63,p55,acc70	(1s)		r87,p51,acc67	(13s)		r33,p79,acc75	(10s)		r18,p86,acc72	(5s)		r80,p55,acc72	(98%c, 71%a, 93%hp, 18%hn) (8s)
supMLP			r66,p63,acc76	(20s)		r66,p60,acc74	(646s)		r68,p56,acc71	(840s)		r70,p64,acc86	(740s)		r70,p61,acc75	(800s)

=> SVD ist schlecht, chi2 schadet nicht bei SS