CIViC sentences: 5114
Abstract sentences: 12605
HoC positive sentences: 4430
HoC negative sentences: 8909
PIBOSO outcome sentences: 3563
PIBOSO other sentences: 2712

Evaluating parameters for preprocessor and classifiers


---------------------------------------------------------------- 
---------------------------------------------------------------- 
words: None chars: (2, 4) 
 
---------------------------------------------------------------- 
----------------------------------------------------------------

Fitting vectorizer and preparing training and test data
No. of features: 43729
No. of features after reduction: 8746 

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.5  0.5]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 15.0 / 600 ( 2.5 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.5124224  0.4875776]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 25.0 / 600 ( 4.16666666667 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.52051046  0.47948954]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 29.0 / 600 ( 4.83333333333 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.52413909  0.47586091]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 31.0 / 600 ( 5.16666666667 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.5255983  0.4744017]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 32.0 / 600 ( 5.33333333333 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.52686232  0.47313768]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 32.0 / 600 ( 5.33333333333 %)

Returning final model after 6 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.98      0.95      0.97       600
        1.0       0.95      0.98      0.97       600

avg / total       0.97      0.97      0.97      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.45  0.55]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 47.0 / 660 ( 7.12121212121 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.49117649  0.50882351]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 61.0 / 660 ( 9.24242424242 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.50129327  0.49870673]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 67.0 / 660 ( 10.1515151515 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.50573325  0.49426675]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 69.0 / 660 ( 10.4545454545 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.50835791  0.49164209]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 72.0 / 660 ( 10.9090909091 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.50998619  0.49001381]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 72.0 / 660 ( 10.9090909091 %)

Returning final model after 6 iterations
Threshold given noise level: 2.51032253838e-11
Unlabelled docs below threshold: 479 of 600 


Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.55607044  0.44392956]
Computing attribute probabilities for 8746 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.55501113  0.44498887]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 68.0 / 600 ( 11.3333333333 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.55587803  0.44412197]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 68.0 / 600 ( 11.3333333333 %)

Delta_i: 0
Returning final model after 2 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.98      0.89      0.93       600
        1.0       0.90      0.98      0.94       600

avg / total       0.94      0.93      0.93      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.4  0.6]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 84.0 / 720 ( 11.6666666667 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.47245747  0.52754253]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 107.0 / 720 ( 14.8611111111 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.48927436  0.51072564]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 115.0 / 720 ( 15.9722222222 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.49529621  0.50470379]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 119.0 / 720 ( 16.5277777778 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.49951102  0.50048898]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 121.0 / 720 ( 16.8055555556 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.50140427  0.49859573]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 125.0 / 720 ( 17.3611111111 %)

Iteration # 7
Building new model using probabilistic labels
Class distribution: [ 0.50342761  0.49657239]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 127.0 / 720 ( 17.6388888889 %)

Iteration # 8
Building new model using probabilistic labels
Class distribution: [ 0.50541483  0.49458517]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 127.0 / 720 ( 17.6388888889 %)

Returning final model after 8 iterations
Threshold given noise level: 0.00177774880785
Unlabelled docs below threshold: 559 of 600 


Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.51768766  0.48231234]
Computing attribute probabilities for 8746 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.53029213  0.46970787]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 39.0 / 600 ( 6.5 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.53254986  0.46745014]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 40.0 / 600 ( 6.66666666667 %)

Delta_i: -77
Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.53338686  0.46661314]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 40.0 / 600 ( 6.66666666667 %)

Delta_i: 0
Returning final model after 3 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.93      0.96       600
        1.0       0.94      0.99      0.96       600

avg / total       0.96      0.96      0.96      1200

Determining RN using Rocchio method

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 499 ( 83.16666666666667 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 508
Iterative SVM converged. Reliable negative examples: 508
Ratio of positive examples misclassified as negative by initial SVM: 0.0866666666667
Ratio of positive examples misclassified as negative by final SVM: 0.0883333333333
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.91      0.84      0.87       600
        1.0       0.85      0.91      0.88       600

avg / total       0.88      0.88      0.88      1200

Determining RN using Cosine Similarity threshold and Rocchio

Computing ranking (cosine similarity to mean positive example)
Choosing Potential Negative examples with ranking threshold
Threshold given noise level: 0.206150023269
Unlabelled docs below threshold: 196 of 600 

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 290 ( 48.333333333333336 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 403
Iteration # 2
Reliable negative examples: 452
Iteration # 3
Reliable negative examples: 462
Iteration # 4
Reliable negative examples: 469
Iteration # 5
Reliable negative examples: 474
Iteration # 6
Reliable negative examples: 476
Iteration # 7
Reliable negative examples: 477
Iteration # 8
Reliable negative examples: 478
Iterative SVM converged. Reliable negative examples: 478
Ratio of positive examples misclassified as negative by initial SVM: 0.0583333333333
Ratio of positive examples misclassified as negative by final SVM: 0.0916666666667
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.90      0.80      0.84       600
        1.0       0.82      0.91      0.86       600

avg / total       0.86      0.85      0.85      1200

Determining RN using Cosine Similarity threshold and Rocchio

Computing ranking (cosine similarity to mean positive example)
Choosing Potential Negative examples with ranking threshold
Threshold given noise level: 0.232249939851
Unlabelled docs below threshold: 310 of 600 

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 373 ( 62.166666666666664 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 448
Iteration # 2
Reliable negative examples: 464
Iteration # 3
Reliable negative examples: 472
Iteration # 4
Reliable negative examples: 477
Iteration # 5
Reliable negative examples: 478
Iteration # 6
Reliable negative examples: 479
Iteration # 7
Reliable negative examples: 480
Iteration # 8
Reliable negative examples: 481
Iteration # 9
Reliable negative examples: 482
Iterative SVM converged. Reliable negative examples: 482
Ratio of positive examples misclassified as negative by initial SVM: 0.0733333333333
Ratio of positive examples misclassified as negative by final SVM: 0.09
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.90      0.80      0.85       600
        1.0       0.82      0.91      0.86       600

avg / total       0.86      0.86      0.86      1200

Determining RN using Rocchio method

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 499 ( 83.16666666666667 %)

Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.54595086  0.45404914]
Computing attribute probabilities for 8746 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.55118482  0.44881518]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 65.0 / 600 ( 10.8333333333 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.55399481  0.44600519]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 66.0 / 600 ( 11.0 %)

Delta_i: 1
Approximated error has grown since last iteration.
Aborting and returning classifier # 1
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.98      0.89      0.93       600
        1.0       0.90      0.98      0.94       600

avg / total       0.94      0.94      0.94      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.45  0.55]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 54.0 / 660 ( 8.18181818182 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.49520478  0.50479522]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 67.0 / 660 ( 10.1515151515 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.50660718  0.49339282]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 73.0 / 660 ( 11.0606060606 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.51183983  0.48816017]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 78.0 / 660 ( 11.8181818182 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.51511879  0.48488121]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 81.0 / 660 ( 12.2727272727 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.5173599  0.4826401]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 83.0 / 660 ( 12.5757575758 %)

Iteration # 7
Building new model using probabilistic labels
Class distribution: [ 0.51934341  0.48065659]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 83.0 / 660 ( 12.5757575758 %)

Returning final model after 7 iterations
Threshold given noise level: 3.06946247461e-05
Unlabelled docs below threshold: 544 of 600 


Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 558
Iteration # 2
Reliable negative examples: 559
Iteration # 3
Reliable negative examples: 560
Iterative SVM converged. Reliable negative examples: 560
Ratio of positive examples misclassified as negative by initial SVM: 0.0883333333333
Ratio of positive examples misclassified as negative by final SVM: 0.0883333333333
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.91      0.90      0.90       600
        1.0       0.90      0.91      0.90       600

avg / total       0.90      0.90      0.90      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.4  0.6]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 98.0 / 720 ( 13.6111111111 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.48157626  0.51842374]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 115.0 / 720 ( 15.9722222222 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.49667127  0.50332873]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 124.0 / 720 ( 17.2222222222 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.50343866  0.49656134]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 127.0 / 720 ( 17.6388888889 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.5066009  0.4933991]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 132.0 / 720 ( 18.3333333333 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.51039925  0.48960075]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 136.0 / 720 ( 18.8888888889 %)

Iteration # 7
Building new model using probabilistic labels
Class distribution: [ 0.51308562  0.48691438]
Computing attribute probabilities for 8746 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 136.0 / 720 ( 18.8888888889 %)

Returning final model after 7 iterations
Threshold given noise level: 0.999999998945
Unlabelled docs below threshold: 578 of 600 


Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 579
Iterative SVM converged. Reliable negative examples: 579
Ratio of positive examples misclassified as negative by initial SVM: 0.0916666666667
Ratio of positive examples misclassified as negative by final SVM: 0.0916666666667
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.91      0.91      0.91       600
        1.0       0.91      0.91      0.91       600

avg / total       0.91      0.91      0.91      1200

There are 24 parameter combinations to be evaluated.

(1.4858543417366945, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10})
(0, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 10})
(0, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 10})
(0, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 10})
(0, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 10})
(0, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 10})
(1.5224932249322494, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 100})
(1.0300429184549356, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 100})
(0, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 100})
(0, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 100})
(0, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 100})
(0, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 100})
(1.5224932249322494, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 1000})
(1.5675572519083973, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 1000})
(1.444, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 1000})
(1.3414258188824661, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 1000})
(1.2487654320987656, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 1000})
(1.1800833333333334, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 1000})
(1.5224932249322494, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10000})
(1.5224932249322494, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 10000})
(1.5102150537634407, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 10000})
(1.5148459383753503, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 10000})
(1.5061475409836067, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 10000})
(1.5224932249322494, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 10000})

Best model has parameters {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 1000} and PU-score 1.56755725191
Building final classifier

---------------------------------------------------------------- 
---------------------------------------------------------------- 
words: None chars: (2, 5) 
 
---------------------------------------------------------------- 
----------------------------------------------------------------

Fitting vectorizer and preparing training and test data
No. of features: 91807
No. of features after reduction: 18372 

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.5  0.5]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 7.0 / 600 ( 1.16666666667 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.50531292  0.49468708]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 8.0 / 600 ( 1.33333333333 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.50689475  0.49310525]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 10.0 / 600 ( 1.66666666667 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.50806614  0.49193386]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 10.0 / 600 ( 1.66666666667 %)

Returning final model after 4 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       600
        1.0       0.98      0.99      0.99       600

avg / total       0.99      0.99      0.99      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.45  0.55]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 40.0 / 660 ( 6.06060606061 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.48363543  0.51636457]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 48.0 / 660 ( 7.27272727273 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.48942335  0.51057665]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 49.0 / 660 ( 7.42424242424 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.49109776  0.50890224]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 50.0 / 660 ( 7.57575757576 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.49174073  0.50825927]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 51.0 / 660 ( 7.72727272727 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.49258486  0.50741514]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 52.0 / 660 ( 7.87878787879 %)

Iteration # 7
Building new model using probabilistic labels
Class distribution: [ 0.49320473  0.50679527]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 53.0 / 660 ( 8.0303030303 %)

Iteration # 8
Building new model using probabilistic labels
Class distribution: [ 0.49451909  0.50548091]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 54.0 / 660 ( 8.18181818182 %)

Iteration # 9
Building new model using probabilistic labels
Class distribution: [ 0.49501409  0.50498591]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 54.0 / 660 ( 8.18181818182 %)

Returning final model after 9 iterations
Threshold given noise level: 1.9502848191e-18
Unlabelled docs below threshold: 514 of 600 


Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.53859964  0.46140036]
Computing attribute probabilities for 18372 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.54006521  0.45993479]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 49.0 / 600 ( 8.16666666667 %)

Returning final model after 1 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.92      0.95       600
        1.0       0.92      0.99      0.96       600

avg / total       0.96      0.96      0.96      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.4  0.6]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 76.0 / 720 ( 10.5555555556 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.46334899  0.53665101]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 90.0 / 720 ( 12.5 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.47423754  0.52576246]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 95.0 / 720 ( 13.1944444444 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.47915404  0.52084596]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 98.0 / 720 ( 13.6111111111 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.48157208  0.51842792]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 101.0 / 720 ( 14.0277777778 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.48408362  0.51591638]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 102.0 / 720 ( 14.1666666667 %)

Iteration # 7
Building new model using probabilistic labels
Class distribution: [ 0.48482642  0.51517358]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 102.0 / 720 ( 14.1666666667 %)

Returning final model after 7 iterations
Threshold given noise level: 5.12250399759e-06
Unlabelled docs below threshold: 577 of 600 


Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.5097706  0.4902294]
Computing attribute probabilities for 18372 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.51633679  0.48366321]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 21.0 / 600 ( 3.5 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.51749558  0.48250442]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 21.0 / 600 ( 3.5 %)

Delta_i: 0
Returning final model after 2 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.96      0.98       600
        1.0       0.97      0.99      0.98       600

avg / total       0.98      0.98      0.98      1200

Determining RN using Rocchio method

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 517 ( 86.16666666666667 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 524
Iterative SVM converged. Reliable negative examples: 524
Ratio of positive examples misclassified as negative by initial SVM: 0.0766666666667
Ratio of positive examples misclassified as negative by final SVM: 0.0766666666667
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.92      0.87      0.89       600
        1.0       0.88      0.92      0.90       600

avg / total       0.90      0.90      0.90      1200

Determining RN using Cosine Similarity threshold and Rocchio

Computing ranking (cosine similarity to mean positive example)
Choosing Potential Negative examples with ranking threshold
Threshold given noise level: 0.179912859034
Unlabelled docs below threshold: 227 of 600 

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 335 ( 55.833333333333336 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 434
Iteration # 2
Reliable negative examples: 468
Iteration # 3
Reliable negative examples: 481
Iteration # 4
Reliable negative examples: 485
Iteration # 5
Reliable negative examples: 488
Iteration # 6
Reliable negative examples: 490
Iterative SVM converged. Reliable negative examples: 490
Ratio of positive examples misclassified as negative by initial SVM: 0.0616666666667
Ratio of positive examples misclassified as negative by final SVM: 0.0733333333333
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.92      0.82      0.86       600
        1.0       0.83      0.93      0.88       600

avg / total       0.88      0.87      0.87      1200

Determining RN using Cosine Similarity threshold and Rocchio

Computing ranking (cosine similarity to mean positive example)
Choosing Potential Negative examples with ranking threshold
Threshold given noise level: 0.203200694636
Unlabelled docs below threshold: 336 of 600 

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 412 ( 68.66666666666667 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 468
Iteration # 2
Reliable negative examples: 486
Iteration # 3
Reliable negative examples: 491
Iteration # 4
Reliable negative examples: 493
Iterative SVM converged. Reliable negative examples: 493
Ratio of positive examples misclassified as negative by initial SVM: 0.0683333333333
Ratio of positive examples misclassified as negative by final SVM: 0.0783333333333
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.91      0.82      0.86       600
        1.0       0.84      0.92      0.88       600

avg / total       0.88      0.87      0.87      1200

Determining RN using Rocchio method

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 517 ( 86.16666666666667 %)

Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.53715309  0.46284691]
Computing attribute probabilities for 18372 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.53873846  0.46126154]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 48.0 / 600 ( 8.0 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.5401944  0.4598056]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 49.0 / 600 ( 8.16666666667 %)

Delta_i: -95
Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.54098278  0.45901722]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 50.0 / 600 ( 8.33333333333 %)

Delta_i: 99
Approximated error has grown since last iteration.
Aborting and returning classifier # 2
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.92      0.95       600
        1.0       0.92      0.99      0.96       600

avg / total       0.96      0.95      0.95      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.45  0.55]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 35.0 / 660 ( 5.30303030303 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.47839074  0.52160926]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 41.0 / 660 ( 6.21212121212 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.48389984  0.51610016]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 43.0 / 660 ( 6.51515151515 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.48618202  0.51381798]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 46.0 / 660 ( 6.9696969697 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.48806902  0.51193098]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 47.0 / 660 ( 7.12121212121 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.48920747  0.51079253]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 47.0 / 660 ( 7.12121212121 %)

Returning final model after 6 iterations
Threshold given noise level: 5.57633193822e-22
Unlabelled docs below threshold: 493 of 600 


Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 533
Iteration # 2
Reliable negative examples: 539
Iteration # 3
Reliable negative examples: 540
Iterative SVM converged. Reliable negative examples: 540
Ratio of positive examples misclassified as negative by initial SVM: 0.0716666666667
Ratio of positive examples misclassified as negative by final SVM: 0.0783333333333
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.92      0.88      0.90       600
        1.0       0.88      0.92      0.90       600

avg / total       0.90      0.90      0.90      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.4  0.6]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 65.0 / 720 ( 9.02777777778 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.45413258  0.54586742]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 71.0 / 720 ( 9.86111111111 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.4595266  0.5404734]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 73.0 / 720 ( 10.1388888889 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.46158043  0.53841957]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 77.0 / 720 ( 10.6944444444 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.46433878  0.53566122]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 78.0 / 720 ( 10.8333333333 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.46515355  0.53484645]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 79.0 / 720 ( 10.9722222222 %)

Iteration # 7
Building new model using probabilistic labels
Class distribution: [ 0.46592273  0.53407727]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 80.0 / 720 ( 11.1111111111 %)

Iteration # 8
Building new model using probabilistic labels
Class distribution: [ 0.46673315  0.53326685]
Computing attribute probabilities for 18372 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 80.0 / 720 ( 11.1111111111 %)

Returning final model after 8 iterations
Threshold given noise level: 4.53717107451e-13
Unlabelled docs below threshold: 544 of 600 


Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 561
Iteration # 2
Reliable negative examples: 562
Iteration # 3
Reliable negative examples: 563
Iterative SVM converged. Reliable negative examples: 563
Ratio of positive examples misclassified as negative by initial SVM: 0.075
Ratio of positive examples misclassified as negative by final SVM: 0.08
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.92      0.91      0.92       600
        1.0       0.91      0.92      0.92       600

avg / total       0.92      0.92      0.92      1200

There are 24 parameter combinations to be evaluated.

(1.7112500000000002, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10})
(0, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 10})
(0, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 10})
(0, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 10})
(0, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 10})
(0, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 10})
(1.7112500000000002, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 100})
(1.0126582278481011, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 100})
(0, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 100})
(0, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 100})
(0, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 100})
(0, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 100})
(1.7112500000000002, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 1000})
(1.6461942257217848, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 1000})
(1.5360730593607306, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 1000})
(1.4687763713080169, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 1000})
(1.3037453183520598, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 1000})
(1.174212271973466, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 1000})
(1.7112500000000002, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10000})
(1.7112500000000002, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 10000})
(1.7112500000000002, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 10000})
(1.7112500000000002, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 10000})
(1.7112500000000002, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 10000})
(1.7112500000000002, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 10000})

Best model has parameters {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10} and PU-score 1.71125
Building final classifier

---------------------------------------------------------------- 
---------------------------------------------------------------- 
words: None chars: (2, 6) 
 
---------------------------------------------------------------- 
----------------------------------------------------------------

Fitting vectorizer and preparing training and test data
No. of features: 158599
No. of features after reduction: 31719 

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.5  0.5]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 5.0 / 600 ( 0.833333333333 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.50419765  0.49580235]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 7.0 / 600 ( 1.16666666667 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.5054958  0.4945042]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 8.0 / 600 ( 1.33333333333 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.50676277  0.49323723]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 10.0 / 600 ( 1.66666666667 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.50801695  0.49198305]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 10.0 / 600 ( 1.66666666667 %)

Returning final model after 5 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       1.00      0.98      0.99       600
        1.0       0.98      1.00      0.99       600

avg / total       0.99      0.99      0.99      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.45  0.55]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 31.0 / 660 ( 4.69696969697 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.47542286  0.52457714]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 39.0 / 660 ( 5.90909090909 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.48274071  0.51725929]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 43.0 / 660 ( 6.51515151515 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.48582453  0.51417547]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 45.0 / 660 ( 6.81818181818 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.48731831  0.51268169]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 45.0 / 660 ( 6.81818181818 %)

Returning final model after 5 iterations
Threshold given noise level: 1.28869115519e-29
Unlabelled docs below threshold: 524 of 600 


Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.53380783  0.46619217]
Computing attribute probabilities for 31719 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.52994028  0.47005972]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 38.0 / 600 ( 6.33333333333 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.53154579  0.46845421]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 38.0 / 600 ( 6.33333333333 %)

Delta_i: 0
Returning final model after 2 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       1.00      0.94      0.97       600
        1.0       0.94      1.00      0.97       600

avg / total       0.97      0.97      0.97      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.4  0.6]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 63.0 / 720 ( 8.75 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.45345894  0.54654106]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 76.0 / 720 ( 10.5555555556 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.46368534  0.53631466]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 80.0 / 720 ( 11.1111111111 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.46686463  0.53313537]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 81.0 / 720 ( 11.25 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.46764821  0.53235179]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 83.0 / 720 ( 11.5277777778 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.46922318  0.53077682]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 84.0 / 720 ( 11.6666666667 %)

Iteration # 7
Building new model using probabilistic labels
Class distribution: [ 0.46988806  0.53011194]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 84.0 / 720 ( 11.6666666667 %)

Returning final model after 7 iterations
Threshold given noise level: 1.40359270582e-22
Unlabelled docs below threshold: 545 of 600 


Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.52401747  0.47598253]
Computing attribute probabilities for 31719 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.52227673  0.47772327]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 27.0 / 600 ( 4.5 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.52255132  0.47744868]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 27.0 / 600 ( 4.5 %)

Delta_i: 54
Approximated error has grown since last iteration.
Aborting and returning classifier # 1
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       1.00      0.95      0.98       600
        1.0       0.96      1.00      0.98       600

avg / total       0.98      0.98      0.98      1200

Determining RN using Rocchio method

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 527 ( 87.83333333333333 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 535
Iteration # 2
Reliable negative examples: 536
Iterative SVM converged. Reliable negative examples: 536
Ratio of positive examples misclassified as negative by initial SVM: 0.075
Ratio of positive examples misclassified as negative by final SVM: 0.075
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.92      0.89      0.91       600
        1.0       0.90      0.93      0.91       600

avg / total       0.91      0.91      0.91      1200

Determining RN using Cosine Similarity threshold and Rocchio

Computing ranking (cosine similarity to mean positive example)
Choosing Potential Negative examples with ranking threshold
Threshold given noise level: 0.163016418568
Unlabelled docs below threshold: 235 of 600 

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 355 ( 59.166666666666664 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 457
Iteration # 2
Reliable negative examples: 489
Iteration # 3
Reliable negative examples: 497
Iteration # 4
Reliable negative examples: 499
Iterative SVM converged. Reliable negative examples: 499
Ratio of positive examples misclassified as negative by initial SVM: 0.06
Ratio of positive examples misclassified as negative by final SVM: 0.0716666666667
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.92      0.83      0.87       600
        1.0       0.85      0.93      0.89       600

avg / total       0.88      0.88      0.88      1200

Determining RN using Cosine Similarity threshold and Rocchio

Computing ranking (cosine similarity to mean positive example)
Choosing Potential Negative examples with ranking threshold
Threshold given noise level: 0.187862934946
Unlabelled docs below threshold: 363 of 600 

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 428 ( 71.33333333333333 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 488
Iteration # 2
Reliable negative examples: 501
Iteration # 3
Reliable negative examples: 503
Iterative SVM converged. Reliable negative examples: 503
Ratio of positive examples misclassified as negative by initial SVM: 0.07
Ratio of positive examples misclassified as negative by final SVM: 0.0716666666667
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.92      0.84      0.88       600
        1.0       0.85      0.93      0.89       600

avg / total       0.89      0.88      0.88      1200

Determining RN using Rocchio method

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 527 ( 87.83333333333333 %)

Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.53238687  0.46761313]
Computing attribute probabilities for 31719 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.53123217  0.46876783]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 39.0 / 600 ( 6.5 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.53215966  0.46784034]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 39.0 / 600 ( 6.5 %)

Delta_i: 0
Returning final model after 2 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       1.00      0.94      0.96       600
        1.0       0.94      1.00      0.97       600

avg / total       0.97      0.97      0.97      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.45  0.55]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 44.0 / 660 ( 6.66666666667 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.48675474  0.51324526]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 50.0 / 660 ( 7.57575757576 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.49121607  0.50878393]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 52.0 / 660 ( 7.87878787879 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.49294504  0.50705496]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 52.0 / 660 ( 7.87878787879 %)

Returning final model after 4 iterations
Threshold given noise level: 1.46062804253e-30
Unlabelled docs below threshold: 521 of 600 


Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 549
Iteration # 2
Reliable negative examples: 553
Iterative SVM converged. Reliable negative examples: 553
Ratio of positive examples misclassified as negative by initial SVM: 0.0666666666667
Ratio of positive examples misclassified as negative by final SVM: 0.0683333333333
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.93      0.91      0.92       600
        1.0       0.91      0.93      0.92       600

avg / total       0.92      0.92      0.92      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.4  0.6]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 64.0 / 720 ( 8.88888888889 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.45377639  0.54622361]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 82.0 / 720 ( 11.3888888889 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.46832702  0.53167298]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 85.0 / 720 ( 11.8055555556 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.47128472  0.52871528]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 88.0 / 720 ( 12.2222222222 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.47342746  0.52657254]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 89.0 / 720 ( 12.3611111111 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.47422497  0.52577503]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 90.0 / 720 ( 12.5 %)

Iteration # 7
Building new model using probabilistic labels
Class distribution: [ 0.47461594  0.52538406]
Computing attribute probabilities for 31719 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 90.0 / 720 ( 12.5 %)

Returning final model after 7 iterations
Threshold given noise level: 3.60341137706e-15
Unlabelled docs below threshold: 571 of 600 


Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 580
Iterative SVM converged. Reliable negative examples: 580
Ratio of positive examples misclassified as negative by initial SVM: 0.0683333333333
Ratio of positive examples misclassified as negative by final SVM: 0.07
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.93      0.94      0.94       600
        1.0       0.94      0.93      0.94       600

avg / total       0.94      0.94      0.94      1200

There are 24 parameter combinations to be evaluated.

(1.5605555555555555, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10})
(0, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 10})
(0, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 10})
(0, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 10})
(0, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 10})
(0, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 10})
(1.4421333333333333, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 100})
(1.00418410041841, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 100})
(0, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 100})
(0, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 100})
(0, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 100})
(0, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 100})
(1.4421333333333333, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 1000})
(1.4678205128205131, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 1000})
(1.4461267605633803, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 1000})
(1.3605967078189301, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 1000})
(1.2897085610200365, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 1000})
(1.1881188118811881, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 1000})
(1.4421333333333333, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10000})
(1.4421333333333333, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 10000})
(1.4421333333333333, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 10000})
(1.4421333333333333, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 10000})
(1.4583333333333333, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 10000})
(1.4981333333333331, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 10000})

Best model has parameters {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10} and PU-score 1.56055555556
Building final classifier

---------------------------------------------------------------- 
---------------------------------------------------------------- 
words: (1, 2) chars: (2, 4) 
 
---------------------------------------------------------------- 
----------------------------------------------------------------

Fitting vectorizer and preparing training and test data
No. of features: 63641
No. of features after reduction: 12728 

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.5  0.5]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 9.0 / 600 ( 1.5 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.50760105  0.49239895]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 13.0 / 600 ( 2.16666666667 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.51122808  0.48877192]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 16.0 / 600 ( 2.66666666667 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.51308403  0.48691597]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 16.0 / 600 ( 2.66666666667 %)

Returning final model after 4 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       600
        1.0       0.97      0.99      0.98       600

avg / total       0.98      0.98      0.98      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.45  0.55]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 43.0 / 660 ( 6.51515151515 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.48607578  0.51392422]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 54.0 / 660 ( 8.18181818182 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.49478769  0.50521231]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 58.0 / 660 ( 8.78787878788 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.49859563  0.50140437]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 63.0 / 660 ( 9.54545454545 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.50198888  0.49801112]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 64.0 / 660 ( 9.69696969697 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.50368718  0.49631282]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 66.0 / 660 ( 10.0 %)

Iteration # 7
Building new model using probabilistic labels
Class distribution: [ 0.5050544  0.4949456]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 66.0 / 660 ( 10.0 %)

Returning final model after 7 iterations
Threshold given noise level: 3.41264758622e-08
Unlabelled docs below threshold: 540 of 600 


Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.52631579  0.47368421]
Computing attribute probabilities for 12728 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.53951849  0.46048151]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 49.0 / 600 ( 8.16666666667 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.5405124  0.4594876]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 49.0 / 600 ( 8.16666666667 %)

Delta_i: 0
Returning final model after 2 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.92      0.95       600
        1.0       0.92      0.99      0.95       600

avg / total       0.96      0.95      0.95      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.4  0.6]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 62.0 / 720 ( 8.61111111111 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.45220999  0.54779001]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 87.0 / 720 ( 12.0833333333 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.47263951  0.52736049]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 95.0 / 720 ( 13.1944444444 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.47847791  0.52152209]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 100.0 / 720 ( 13.8888888889 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.48325095  0.51674905]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 102.0 / 720 ( 14.1666666667 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.48546815  0.51453185]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 105.0 / 720 ( 14.5833333333 %)

Iteration # 7
Building new model using probabilistic labels
Class distribution: [ 0.48741791  0.51258209]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 107.0 / 720 ( 14.8611111111 %)

Iteration # 8
Building new model using probabilistic labels
Class distribution: [ 0.48895069  0.51104931]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 108.0 / 720 ( 15.0 %)

Iteration # 9
Building new model using probabilistic labels
Class distribution: [ 0.49051893  0.50948107]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 111.0 / 720 ( 15.4166666667 %)

Iteration # 10
Building new model using probabilistic labels
Class distribution: [ 0.49255325  0.50744675]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 111.0 / 720 ( 15.4166666667 %)

Returning final model after 10 iterations
Threshold given noise level: 1.91434879616e-06
Unlabelled docs below threshold: 547 of 600 


Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.52310375  0.47689625]
Computing attribute probabilities for 12728 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.53836122  0.46163878]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 46.0 / 600 ( 7.66666666667 %)

Returning final model after 1 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.92      0.95       600
        1.0       0.93      0.99      0.96       600

avg / total       0.96      0.96      0.96      1200

Determining RN using Rocchio method

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 521 ( 86.83333333333333 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 526
Iteration # 2
Reliable negative examples: 527
Iterative SVM converged. Reliable negative examples: 527
Ratio of positive examples misclassified as negative by initial SVM: 0.0166666666667
Ratio of positive examples misclassified as negative by final SVM: 0.0183333333333
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.98      0.88      0.93       600
        1.0       0.89      0.98      0.93       600

avg / total       0.93      0.93      0.93      1200

Determining RN using Cosine Similarity threshold and Rocchio

Computing ranking (cosine similarity to mean positive example)
Choosing Potential Negative examples with ranking threshold
Threshold given noise level: 0.12212962767
Unlabelled docs below threshold: 223 of 600 

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 321 ( 53.5 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 371
Iteration # 2
Reliable negative examples: 400
Iteration # 3
Reliable negative examples: 423
Iteration # 4
Reliable negative examples: 438
Iteration # 5
Reliable negative examples: 458
Iteration # 6
Reliable negative examples: 472
Iteration # 7
Reliable negative examples: 474
Iteration # 8
Reliable negative examples: 475
Iterative SVM converged. Reliable negative examples: 475
Ratio of positive examples misclassified as negative by initial SVM: 0.0133333333333
Ratio of positive examples misclassified as negative by final SVM: 0.0183333333333
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.98      0.79      0.87       600
        1.0       0.82      0.98      0.90       600

avg / total       0.90      0.89      0.89      1200

Determining RN using Cosine Similarity threshold and Rocchio

Computing ranking (cosine similarity to mean positive example)
Choosing Potential Negative examples with ranking threshold
Threshold given noise level: 0.141134914388
Unlabelled docs below threshold: 280 of 600 

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 366 ( 61.0 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 409
Iteration # 2
Reliable negative examples: 427
Iteration # 3
Reliable negative examples: 439
Iteration # 4
Reliable negative examples: 454
Iteration # 5
Reliable negative examples: 467
Iteration # 6
Reliable negative examples: 478
Iteration # 7
Reliable negative examples: 482
Iteration # 8
Reliable negative examples: 484
Iteration # 9
Reliable negative examples: 485
Iterative SVM converged. Reliable negative examples: 485
Ratio of positive examples misclassified as negative by initial SVM: 0.0166666666667
Ratio of positive examples misclassified as negative by final SVM: 0.02
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.98      0.81      0.88       600
        1.0       0.84      0.98      0.90       600

avg / total       0.91      0.89      0.89      1200

Determining RN using Rocchio method

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 521 ( 86.83333333333333 %)

Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.5352364  0.4647636]
Computing attribute probabilities for 12728 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.54476709  0.45523291]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 56.0 / 600 ( 9.33333333333 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.54673035  0.45326965]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 58.0 / 600 ( 9.66666666667 %)

Delta_i: 2
Approximated error has grown since last iteration.
Aborting and returning classifier # 1
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.91      0.95       600
        1.0       0.91      0.99      0.95       600

avg / total       0.95      0.95      0.95      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.45  0.55]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 44.0 / 660 ( 6.66666666667 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.48723093  0.51276907]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 53.0 / 660 ( 8.0303030303 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.49439721  0.50560279]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 57.0 / 660 ( 8.63636363636 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.49839431  0.50160569]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 63.0 / 660 ( 9.54545454545 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.50209238  0.49790762]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 65.0 / 660 ( 9.84848484848 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.50441244  0.49558756]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 67.0 / 660 ( 10.1515151515 %)

Iteration # 7
Building new model using probabilistic labels
Class distribution: [ 0.50605401  0.49394599]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 67.0 / 660 ( 10.1515151515 %)

Returning final model after 7 iterations
Threshold given noise level: 1.59162707323e-13
Unlabelled docs below threshold: 498 of 600 


Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 532
Iteration # 2
Reliable negative examples: 534
Iteration # 3
Reliable negative examples: 535
Iterative SVM converged. Reliable negative examples: 535
Ratio of positive examples misclassified as negative by initial SVM: 0.0166666666667
Ratio of positive examples misclassified as negative by final SVM: 0.0166666666667
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.98      0.89      0.93       600
        1.0       0.90      0.98      0.94       600

avg / total       0.94      0.93      0.93      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.4  0.6]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 72.0 / 720 ( 10.0 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.46009473  0.53990527]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 87.0 / 720 ( 12.0833333333 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.47348404  0.52651596]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 94.0 / 720 ( 13.0555555556 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.47904269  0.52095731]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 100.0 / 720 ( 13.8888888889 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.48347373  0.51652627]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 101.0 / 720 ( 14.0277777778 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.48469387  0.51530613]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 104.0 / 720 ( 14.4444444444 %)

Iteration # 7
Building new model using probabilistic labels
Class distribution: [ 0.48691716  0.51308284]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 105.0 / 720 ( 14.5833333333 %)

Iteration # 8
Building new model using probabilistic labels
Class distribution: [ 0.48782219  0.51217781]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 106.0 / 720 ( 14.7222222222 %)

Iteration # 9
Building new model using probabilistic labels
Class distribution: [ 0.48859121  0.51140879]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 108.0 / 720 ( 15.0 %)

Iteration # 10
Building new model using probabilistic labels
Class distribution: [ 0.48989515  0.51010485]
Computing attribute probabilities for 12728 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 108.0 / 720 ( 15.0 %)

Returning final model after 10 iterations
Threshold given noise level: 1.81331789728e-07
Unlabelled docs below threshold: 545 of 600 


Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 559
Iterative SVM converged. Reliable negative examples: 559
Ratio of positive examples misclassified as negative by initial SVM: 0.0183333333333
Ratio of positive examples misclassified as negative by final SVM: 0.0183333333333
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.98      0.92      0.95       600
        1.0       0.93      0.98      0.95       600

avg / total       0.95      0.95      0.95      1200

There are 24 parameter combinations to be evaluated.

(1.5102150537634407, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10})
(0, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 10})
(0, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 10})
(0, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 10})
(0, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 10})
(0, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 10})
(1.5185950413223142, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 100})
(1.1569444444444446, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 100})
(1.0126582278481011, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 100})
(0, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 100})
(0, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 100})
(0, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 100})
(1.5185950413223142, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 1000})
(1.5388440860215054, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 1000})
(1.5556818181818182, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 1000})
(1.5471428571428569, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 1000})
(1.5574944071588366, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 1000})
(1.4595387840670859, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 1000})
(1.5185950413223142, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10000})
(1.5185950413223142, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 10000})
(1.5185950413223142, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 10000})
(1.5185950413223142, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 10000})
(1.5185950413223142, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 10000})
(1.53125, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 10000})

Best model has parameters {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 1000} and PU-score 1.55749440716
Building final classifier

---------------------------------------------------------------- 
---------------------------------------------------------------- 
words: (1, 2) chars: (2, 5) 
 
---------------------------------------------------------------- 
----------------------------------------------------------------

Fitting vectorizer and preparing training and test data
No. of features: 111719
No. of features after reduction: 22343 

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.5  0.5]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 7.0 / 600 ( 1.16666666667 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.50620483  0.49379517]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 11.0 / 600 ( 1.83333333333 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.50923751  0.49076249]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 12.0 / 600 ( 2.0 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.51002645  0.48997355]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 12.0 / 600 ( 2.0 %)

Returning final model after 4 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       1.00      0.98      0.99       600
        1.0       0.98      1.00      0.99       600

avg / total       0.99      0.99      0.99      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.45  0.55]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 37.0 / 660 ( 5.60606060606 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.48151628  0.51848372]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 46.0 / 660 ( 6.9696969697 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.48899503  0.51100497]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 49.0 / 660 ( 7.42424242424 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.49103067  0.50896933]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 51.0 / 660 ( 7.72727272727 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.49219837  0.50780163]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 52.0 / 660 ( 7.87878787879 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.49333206  0.50666794]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 52.0 / 660 ( 7.87878787879 %)

Returning final model after 6 iterations
Threshold given noise level: 1.03404750792e-13
Unlabelled docs below threshold: 548 of 600 


Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.52264808  0.47735192]
Computing attribute probabilities for 22343 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.53632882  0.46367118]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 44.0 / 600 ( 7.33333333333 %)

Returning final model after 1 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       1.00      0.93      0.96       600
        1.0       0.93      1.00      0.96       600

avg / total       0.96      0.96      0.96      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.4  0.6]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 51.0 / 720 ( 7.08333333333 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.44340558  0.55659442]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 68.0 / 720 ( 9.44444444444 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.45583966  0.54416034]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 72.0 / 720 ( 10.0 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.46025965  0.53974035]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 75.0 / 720 ( 10.4166666667 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.46232962  0.53767038]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 76.0 / 720 ( 10.5555555556 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.4639059  0.5360941]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 78.0 / 720 ( 10.8333333333 %)

Iteration # 7
Building new model using probabilistic labels
Class distribution: [ 0.46502521  0.53497479]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 80.0 / 720 ( 11.1111111111 %)

Iteration # 8
Building new model using probabilistic labels
Class distribution: [ 0.46669821  0.53330179]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 82.0 / 720 ( 11.3888888889 %)

Iteration # 9
Building new model using probabilistic labels
Class distribution: [ 0.46818812  0.53181188]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 84.0 / 720 ( 11.6666666667 %)

Iteration # 10
Building new model using probabilistic labels
Class distribution: [ 0.46997892  0.53002108]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 85.0 / 720 ( 11.8055555556 %)

Iteration # 11
Building new model using probabilistic labels
Class distribution: [ 0.4709172  0.5290828]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 86.0 / 720 ( 11.9444444444 %)

Iteration # 12
Building new model using probabilistic labels
Class distribution: [ 0.47170291  0.52829709]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 87.0 / 720 ( 12.0833333333 %)

Iteration # 13
Building new model using probabilistic labels
Class distribution: [ 0.47210201  0.52789799]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 87.0 / 720 ( 12.0833333333 %)

Returning final model after 13 iterations
Threshold given noise level: 1.5030876049e-14
Unlabelled docs below threshold: 545 of 600 


Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.52401747  0.47598253]
Computing attribute probabilities for 22343 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.53774812  0.46225188]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 46.0 / 600 ( 7.66666666667 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.53830214  0.46169786]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 46.0 / 600 ( 7.66666666667 %)

Delta_i: 0
Returning final model after 2 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       1.00      0.92      0.96       600
        1.0       0.93      1.00      0.96       600

avg / total       0.96      0.96      0.96      1200

Determining RN using Rocchio method

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 536 ( 89.33333333333333 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 539
Iteration # 2
Reliable negative examples: 540
Iterative SVM converged. Reliable negative examples: 540
Ratio of positive examples misclassified as negative by initial SVM: 0.01
Ratio of positive examples misclassified as negative by final SVM: 0.01
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.90      0.94       600
        1.0       0.91      0.99      0.95       600

avg / total       0.95      0.94      0.94      1200

Determining RN using Cosine Similarity threshold and Rocchio

Computing ranking (cosine similarity to mean positive example)
Choosing Potential Negative examples with ranking threshold
Threshold given noise level: 0.11793566124
Unlabelled docs below threshold: 256 of 600 

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 328 ( 54.666666666666664 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 374
Iteration # 2
Reliable negative examples: 394
Iteration # 3
Reliable negative examples: 405
Iteration # 4
Reliable negative examples: 413
Iteration # 5
Reliable negative examples: 426
Iteration # 6
Reliable negative examples: 440
Iteration # 7
Reliable negative examples: 452
Iteration # 8
Reliable negative examples: 461
Iteration # 9
Reliable negative examples: 465
Iteration # 10
Reliable negative examples: 468
Iteration # 11
Reliable negative examples: 470
Iterative SVM converged. Reliable negative examples: 470
Ratio of positive examples misclassified as negative by initial SVM: 0.00666666666667
Ratio of positive examples misclassified as negative by final SVM: 0.00666666666667
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.78      0.88       600
        1.0       0.82      0.99      0.90       600

avg / total       0.91      0.89      0.89      1200

Determining RN using Cosine Similarity threshold and Rocchio

Computing ranking (cosine similarity to mean positive example)
Choosing Potential Negative examples with ranking threshold
Threshold given noise level: 0.134997442265
Unlabelled docs below threshold: 333 of 600 

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 381 ( 63.5 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 414
Iteration # 2
Reliable negative examples: 431
Iteration # 3
Reliable negative examples: 442
Iteration # 4
Reliable negative examples: 452
Iteration # 5
Reliable negative examples: 461
Iteration # 6
Reliable negative examples: 467
Iteration # 7
Reliable negative examples: 471
Iterative SVM converged. Reliable negative examples: 471
Ratio of positive examples misclassified as negative by initial SVM: 0.00666666666667
Ratio of positive examples misclassified as negative by final SVM: 0.00666666666667
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.79      0.88       600
        1.0       0.82      0.99      0.90       600

avg / total       0.91      0.89      0.89      1200

Determining RN using Rocchio method

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 536 ( 89.33333333333333 %)

Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.52816901  0.47183099]
Computing attribute probabilities for 22343 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.53774494  0.46225506]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 47.0 / 600 ( 7.83333333333 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.53905689  0.46094311]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 48.0 / 600 ( 8.0 %)

Delta_i: 1
Approximated error has grown since last iteration.
Aborting and returning classifier # 1
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.92      0.96       600
        1.0       0.93      0.99      0.96       600

avg / total       0.96      0.96      0.96      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.45  0.55]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 36.0 / 660 ( 5.45454545455 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.48000751  0.51999249]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 47.0 / 660 ( 7.12121212121 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.4895136  0.5104864]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 52.0 / 660 ( 7.87878787879 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.49330978  0.50669022]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 54.0 / 660 ( 8.18181818182 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.49425033  0.50574967]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 54.0 / 660 ( 8.18181818182 %)

Returning final model after 5 iterations
Threshold given noise level: 1.47886951252e-22
Unlabelled docs below threshold: 494 of 600 


Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 525
Iteration # 2
Reliable negative examples: 533
Iteration # 3
Reliable negative examples: 535
Iteration # 4
Reliable negative examples: 536
Iterative SVM converged. Reliable negative examples: 536
Ratio of positive examples misclassified as negative by initial SVM: 0.00833333333333
Ratio of positive examples misclassified as negative by final SVM: 0.00833333333333
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.89      0.94       600
        1.0       0.90      0.99      0.94       600

avg / total       0.95      0.94      0.94      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.4  0.6]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 59.0 / 720 ( 8.19444444444 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.44940987  0.55059013]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 75.0 / 720 ( 10.4166666667 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.46088313  0.53911687]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 79.0 / 720 ( 10.9722222222 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.46632594  0.53367406]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 83.0 / 720 ( 11.5277777778 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.46932881  0.53067119]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 84.0 / 720 ( 11.6666666667 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.47004581  0.52995419]
Computing attribute probabilities for 22343 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 84.0 / 720 ( 11.6666666667 %)

Returning final model after 6 iterations
Threshold given noise level: 3.42097504077e-12
Unlabelled docs below threshold: 550 of 600 


Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 561
Iteration # 2
Reliable negative examples: 563
Iterative SVM converged. Reliable negative examples: 563
Ratio of positive examples misclassified as negative by initial SVM: 0.00666666666667
Ratio of positive examples misclassified as negative by final SVM: 0.00666666666667
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.94      0.96       600
        1.0       0.94      0.99      0.97       600

avg / total       0.97      0.96      0.96      1200

There are 24 parameter combinations to be evaluated.

(1.47, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10})
(0, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 10})
(0, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 10})
(0, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 10})
(0, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 10})
(0, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 10})
(1.47, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 100})
(1.3186813186813187, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 100})
(1.0256410256410258, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 100})
(0, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 100})
(0, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 100})
(0, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 100})
(1.47, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 1000})
(1.47, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 1000})
(1.4818548387096773, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 1000})
(1.5144179894179894, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 1000})
(1.4678205128205131, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 1000})
(1.4134567901234569, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 1000})
(1.47, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10000})
(1.47, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 10000})
(1.47, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 10000})
(1.47, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 10000})
(1.47, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 10000})
(1.47, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 10000})

Best model has parameters {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 1000} and PU-score 1.51441798942
Building final classifier

---------------------------------------------------------------- 
---------------------------------------------------------------- 
words: (1, 2) chars: (2, 6) 
 
---------------------------------------------------------------- 
----------------------------------------------------------------

Fitting vectorizer and preparing training and test data
No. of features: 178511
No. of features after reduction: 35702 

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.5  0.5]
Computing attribute probabilities for 35702 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 7.0 / 600 ( 1.16666666667 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.50573383  0.49426617]
Computing attribute probabilities for 35702 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 7.0 / 600 ( 1.16666666667 %)

Returning final model after 2 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       1.00      0.99      0.99       600
        1.0       0.99      1.00      0.99       600

avg / total       0.99      0.99      0.99      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.45  0.55]
Computing attribute probabilities for 35702 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 33.0 / 660 ( 5.0 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.47750426  0.52249574]
Computing attribute probabilities for 35702 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 35.0 / 660 ( 5.30303030303 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.47943167  0.52056833]
Computing attribute probabilities for 35702 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 39.0 / 660 ( 5.90909090909 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.481775  0.518225]
Computing attribute probabilities for 35702 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 39.0 / 660 ( 5.90909090909 %)

Returning final model after 4 iterations
Threshold given noise level: 3.17634011829e-45
Unlabelled docs below threshold: 452 of 600 


Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.57034221  0.42965779]
Computing attribute probabilities for 35702 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.54983197  0.45016803]
Computing attribute probabilities for 35702 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 59.0 / 600 ( 9.83333333333 %)

Returning final model after 1 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       1.00      0.90      0.95       600
        1.0       0.91      1.00      0.95       600

avg / total       0.96      0.95      0.95      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.4  0.6]
Computing attribute probabilities for 35702 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 53.0 / 720 ( 7.36111111111 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.44400977  0.55599023]
Computing attribute probabilities for 35702 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 68.0 / 720 ( 9.44444444444 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.45641701  0.54358299]
Computing attribute probabilities for 35702 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 71.0 / 720 ( 9.86111111111 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.45920007  0.54079993]
Computing attribute probabilities for 35702 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 73.0 / 720 ( 10.1388888889 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.46119512  0.53880488]
Computing attribute probabilities for 35702 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 74.0 / 720 ( 10.2777777778 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.46195561  0.53804439]
Computing attribute probabilities for 35702 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 75.0 / 720 ( 10.4166666667 %)

Iteration # 7
Building new model using probabilistic labels
Class distribution: [ 0.46250047  0.53749953]
Computing attribute probabilities for 35702 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 75.0 / 720 ( 10.4166666667 %)

Returning final model after 7 iterations
Threshold given noise level: 1.2731772853e-18
Unlabelled docs below threshold: 568 of 600 


Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.51369863  0.48630137]
Computing attribute probabilities for 35702 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.52173275  0.47826725]
Computing attribute probabilities for 35702 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 27.0 / 600 ( 4.5 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.52219654  0.47780346]
Computing attribute probabilities for 35702 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 27.0 / 600 ( 4.5 %)

Delta_i: 0
Returning final model after 2 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       1.00      0.95      0.98       600
        1.0       0.96      1.00      0.98       600

avg / total       0.98      0.98      0.98      1200

Determining RN using Rocchio method

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 541 ( 90.16666666666667 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 545
Iteration # 2
Reliable negative examples: 546
Iterative SVM converged. Reliable negative examples: 546
Ratio of positive examples misclassified as negative by initial SVM: 0.0
Ratio of positive examples misclassified as negative by final SVM: 0.0
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       1.00      0.91      0.95       600
        1.0       0.92      1.00      0.96       600

avg / total       0.96      0.95      0.95      1200

Determining RN using Cosine Similarity threshold and Rocchio

Computing ranking (cosine similarity to mean positive example)
Choosing Potential Negative examples with ranking threshold
Threshold given noise level: 0.113128621346
Unlabelled docs below threshold: 258 of 600 

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 326 ( 54.333333333333336 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 367
Iteration # 2
Reliable negative examples: 383
Iteration # 3
Reliable negative examples: 395
Iteration # 4
Reliable negative examples: 401
Iteration # 5
Reliable negative examples: 411
Iteration # 6
Reliable negative examples: 421
Iteration # 7
Reliable negative examples: 435
Iteration # 8
Reliable negative examples: 446
Iteration # 9
Reliable negative examples: 456
Iteration # 10
Reliable negative examples: 461
Iteration # 11
Reliable negative examples: 463
Iteration # 12
Reliable negative examples: 467
Iterative SVM converged. Reliable negative examples: 467
Ratio of positive examples misclassified as negative by initial SVM: 0.0
Ratio of positive examples misclassified as negative by final SVM: 0.0
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       1.00      0.78      0.88       600
        1.0       0.82      1.00      0.90       600

avg / total       0.91      0.89      0.89      1200

Determining RN using Cosine Similarity threshold and Rocchio

Computing ranking (cosine similarity to mean positive example)
Choosing Potential Negative examples with ranking threshold
Threshold given noise level: 0.129295129517
Unlabelled docs below threshold: 329 of 600 

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 374 ( 62.333333333333336 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 407
Iteration # 2
Reliable negative examples: 423
Iteration # 3
Reliable negative examples: 437
Iteration # 4
Reliable negative examples: 451
Iteration # 5
Reliable negative examples: 461
Iteration # 6
Reliable negative examples: 467
Iteration # 7
Reliable negative examples: 474
Iteration # 8
Reliable negative examples: 475
Iteration # 9
Reliable negative examples: 476
Iteration # 10
Reliable negative examples: 477
Iterative SVM converged. Reliable negative examples: 477
Ratio of positive examples misclassified as negative by initial SVM: 0.0
Ratio of positive examples misclassified as negative by final SVM: 0.0
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       1.00      0.80      0.89       600
        1.0       0.83      1.00      0.91       600

avg / total       0.91      0.90      0.90      1200

Determining RN using Rocchio method

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 541 ( 90.16666666666667 %)

Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.52585451  0.47414549]
Computing attribute probabilities for 35702 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.52817821  0.47182179]
Computing attribute probabilities for 35702 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 34.0 / 600 ( 5.66666666667 %)

Returning final model after 1 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       1.00      0.94      0.97       600
        1.0       0.95      1.00      0.97       600

avg / total       0.97      0.97      0.97      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.45  0.55]
Computing attribute probabilities for 35702 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 37.0 / 660 ( 5.60606060606 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.48119616  0.51880384]
Computing attribute probabilities for 35702 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 44.0 / 660 ( 6.66666666667 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.48664985  0.51335015]
Computing attribute probabilities for 35702 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 45.0 / 660 ( 6.81818181818 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.48744543  0.51255457]
Computing attribute probabilities for 35702 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 45.0 / 660 ( 6.81818181818 %)

Returning final model after 4 iterations
Threshold given noise level: 4.38513017531e-30
Unlabelled docs below threshold: 533 of 600 


Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 553
Iteration # 2
Reliable negative examples: 556
Iterative SVM converged. Reliable negative examples: 556
Ratio of positive examples misclassified as negative by initial SVM: 0.0
Ratio of positive examples misclassified as negative by final SVM: 0.0
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       1.00      0.93      0.96       600
        1.0       0.93      1.00      0.96       600

avg / total       0.97      0.96      0.96      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.4  0.6]
Computing attribute probabilities for 35702 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 55.0 / 720 ( 7.63888888889 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.44589863  0.55410137]
Computing attribute probabilities for 35702 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 75.0 / 720 ( 10.4166666667 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.46208912  0.53791088]
Computing attribute probabilities for 35702 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 78.0 / 720 ( 10.8333333333 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.4651017  0.5348983]
Computing attribute probabilities for 35702 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 80.0 / 720 ( 11.1111111111 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.46664389  0.53335611]
Computing attribute probabilities for 35702 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 81.0 / 720 ( 11.25 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.46750004  0.53249996]
Computing attribute probabilities for 35702 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 81.0 / 720 ( 11.25 %)

Returning final model after 6 iterations
Threshold given noise level: 3.06602313805e-21
Unlabelled docs below threshold: 562 of 600 


Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 572
Iteration # 2
Reliable negative examples: 573
Iterative SVM converged. Reliable negative examples: 573
Ratio of positive examples misclassified as negative by initial SVM: 0.0
Ratio of positive examples misclassified as negative by final SVM: 0.0
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       1.00      0.95      0.98       600
        1.0       0.96      1.00      0.98       600

avg / total       0.98      0.98      0.98      1200

There are 24 parameter combinations to be evaluated.

(1.5804878048780491, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10})
(0, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 10})
(0, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 10})
(0, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 10})
(0, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 10})
(0, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 10})
(1.5804878048780491, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 100})
(1.3264534883720929, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 100})
(1.0256410256410258, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 100})
(0, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 100})
(0, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 100})
(0, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 100})
(1.5804878048780491, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 1000})
(1.5804878048780491, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 1000})
(1.5804878048780491, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 1000})
(1.5804878048780491, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 1000})
(1.5591863517060367, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 1000})
(1.5049751243781093, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 1000})
(1.5804878048780491, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10000})
(1.5804878048780491, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 10000})
(1.5804878048780491, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 10000})
(1.5804878048780491, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 10000})
(1.5804878048780491, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 10000})
(1.5804878048780491, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 10000})

Best model has parameters {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10} and PU-score 1.58048780488
Building final classifier

---------------------------------------------------------------- 
---------------------------------------------------------------- 
words: (1, 3) chars: (2, 4) 
 
---------------------------------------------------------------- 
----------------------------------------------------------------

Fitting vectorizer and preparing training and test data
No. of features: 85649
No. of features after reduction: 17129 

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.5  0.5]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 9.0 / 600 ( 1.5 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.50765835  0.49234165]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 12.0 / 600 ( 2.0 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.51067306  0.48932694]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 16.0 / 600 ( 2.66666666667 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.51314281  0.48685719]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 17.0 / 600 ( 2.83333333333 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.51416487  0.48583513]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 17.0 / 600 ( 2.83333333333 %)

Returning final model after 5 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       600
        1.0       0.97      0.99      0.98       600

avg / total       0.98      0.98      0.98      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.45  0.55]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 40.0 / 660 ( 6.06060606061 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.48332884  0.51667116]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 46.0 / 660 ( 6.9696969697 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.48877205  0.51122795]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 49.0 / 660 ( 7.42424242424 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.49086131  0.50913869]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 50.0 / 660 ( 7.57575757576 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.49168205  0.50831795]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 50.0 / 660 ( 7.57575757576 %)

Returning final model after 5 iterations
Threshold given noise level: 7.93879347383e-16
Unlabelled docs below threshold: 519 of 600 


Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.53619303  0.46380697]
Computing attribute probabilities for 17129 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.54099803  0.45900197]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 50.0 / 600 ( 8.33333333333 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.54151283  0.45848717]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 50.0 / 600 ( 8.33333333333 %)

Delta_i: 0
Returning final model after 2 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.92      0.95       600
        1.0       0.92      0.99      0.96       600

avg / total       0.96      0.96      0.96      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.4  0.6]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 55.0 / 720 ( 7.63888888889 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.44576933  0.55423067]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 72.0 / 720 ( 10.0 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.46011219  0.53988781]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 80.0 / 720 ( 11.1111111111 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.46667061  0.53332939]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 81.0 / 720 ( 11.25 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.46772725  0.53227275]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 83.0 / 720 ( 11.5277777778 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.46895863  0.53104137]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 83.0 / 720 ( 11.5277777778 %)

Returning final model after 6 iterations
Threshold given noise level: 4.45474100769e-11
Unlabelled docs below threshold: 541 of 600 


Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.52585451  0.47414549]
Computing attribute probabilities for 17129 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.53292689  0.46707311]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 40.0 / 600 ( 6.66666666667 %)

Returning final model after 1 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.93      0.96       600
        1.0       0.94      0.99      0.97       600

avg / total       0.97      0.96      0.96      1200

Determining RN using Rocchio method

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 525 ( 87.5 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 533
Iteration # 2
Reliable negative examples: 535
Iteration # 3
Reliable negative examples: 536
Iterative SVM converged. Reliable negative examples: 536
Ratio of positive examples misclassified as negative by initial SVM: 0.0283333333333
Ratio of positive examples misclassified as negative by final SVM: 0.0266666666667
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.97      0.89      0.93       600
        1.0       0.90      0.97      0.94       600

avg / total       0.94      0.93      0.93      1200

Determining RN using Cosine Similarity threshold and Rocchio

Computing ranking (cosine similarity to mean positive example)
Choosing Potential Negative examples with ranking threshold
Threshold given noise level: 0.131618658991
Unlabelled docs below threshold: 213 of 600 

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 309 ( 51.5 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 400
Iteration # 2
Reliable negative examples: 444
Iteration # 3
Reliable negative examples: 459
Iteration # 4
Reliable negative examples: 464
Iteration # 5
Reliable negative examples: 465
Iterative SVM converged. Reliable negative examples: 465
Ratio of positive examples misclassified as negative by initial SVM: 0.00666666666667
Ratio of positive examples misclassified as negative by final SVM: 0.0266666666667
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.97      0.78      0.86       600
        1.0       0.81      0.97      0.89       600

avg / total       0.89      0.87      0.87      1200

Determining RN using Cosine Similarity threshold and Rocchio

Computing ranking (cosine similarity to mean positive example)
Choosing Potential Negative examples with ranking threshold
Threshold given noise level: 0.155519416778
Unlabelled docs below threshold: 301 of 600 

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 399 ( 66.5 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 470
Iteration # 2
Reliable negative examples: 494
Iteration # 3
Reliable negative examples: 502
Iteration # 4
Reliable negative examples: 505
Iteration # 5
Reliable negative examples: 506
Iteration # 6
Reliable negative examples: 509
Iteration # 7
Reliable negative examples: 511
Iteration # 8
Reliable negative examples: 513
Iterative SVM converged. Reliable negative examples: 513
Ratio of positive examples misclassified as negative by initial SVM: 0.015
Ratio of positive examples misclassified as negative by final SVM: 0.0233333333333
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.97      0.85      0.91       600
        1.0       0.87      0.98      0.92       600

avg / total       0.92      0.92      0.92      1200

Determining RN using Rocchio method

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 525 ( 87.5 %)

Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.53333333  0.46666667]
Computing attribute probabilities for 17129 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.53626036  0.46373964]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 45.0 / 600 ( 7.5 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.53748462  0.46251538]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 45.0 / 600 ( 7.5 %)

Delta_i: 0
Returning final model after 2 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.93      0.96       600
        1.0       0.93      0.99      0.96       600

avg / total       0.96      0.96      0.96      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.45  0.55]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 31.0 / 660 ( 4.69696969697 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.47586498  0.52413502]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 38.0 / 660 ( 5.75757575758 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.48229955  0.51770045]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 44.0 / 660 ( 6.66666666667 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.48694844  0.51305156]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 49.0 / 660 ( 7.42424242424 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.49077967  0.50922033]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 50.0 / 660 ( 7.57575757576 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.49191341  0.50808659]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 51.0 / 660 ( 7.72727272727 %)

Iteration # 7
Building new model using probabilistic labels
Class distribution: [ 0.49254883  0.50745117]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 52.0 / 660 ( 7.87878787879 %)

Iteration # 8
Building new model using probabilistic labels
Class distribution: [ 0.49298566  0.50701434]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 52.0 / 660 ( 7.87878787879 %)

Returning final model after 8 iterations
Threshold given noise level: 8.9224302211e-15
Unlabelled docs below threshold: 522 of 600 


Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 548
Iteration # 2
Reliable negative examples: 550
Iterative SVM converged. Reliable negative examples: 550
Ratio of positive examples misclassified as negative by initial SVM: 0.0233333333333
Ratio of positive examples misclassified as negative by final SVM: 0.025
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.97      0.91      0.94       600
        1.0       0.92      0.97      0.94       600

avg / total       0.94      0.94      0.94      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.4  0.6]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 56.0 / 720 ( 7.77777777778 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.44645353  0.55354647]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 66.0 / 720 ( 9.16666666667 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.45590408  0.54409592]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 73.0 / 720 ( 10.1388888889 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.46057449  0.53942551]
Computing attribute probabilities for 17129 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 73.0 / 720 ( 10.1388888889 %)

Returning final model after 4 iterations
Threshold given noise level: 1.02342148513e-11
Unlabelled docs below threshold: 540 of 600 


Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 560
Iteration # 2
Reliable negative examples: 561
Iteration # 3
Reliable negative examples: 562
Iterative SVM converged. Reliable negative examples: 562
Ratio of positive examples misclassified as negative by initial SVM: 0.0266666666667
Ratio of positive examples misclassified as negative by final SVM: 0.0233333333333
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.98      0.93      0.95       600
        1.0       0.93      0.98      0.95       600

avg / total       0.95      0.95      0.95      1200

There are 24 parameter combinations to be evaluated.

(1.5112535612535611, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10})
(0, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 10})
(0, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 10})
(0, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 10})
(0, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 10})
(0, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 10})
(1.4784057971014493, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 100})
(1.1374407582938388, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 100})
(0, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 100})
(0, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 100})
(0, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 100})
(0, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 100})
(1.4784057971014493, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 1000})
(1.5148459383753503, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 1000})
(1.51875, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 1000})
(1.4560049019607844, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 1000})
(1.4518518518518519, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 1000})
(1.4719354838709675, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 1000})
(1.4784057971014493, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10000})
(1.4784057971014493, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 10000})
(1.4784057971014493, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 10000})
(1.4784057971014493, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 10000})
(1.4784057971014493, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 10000})
(1.4784057971014493, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 10000})

Best model has parameters {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 1000} and PU-score 1.51875
Building final classifier

---------------------------------------------------------------- 
---------------------------------------------------------------- 
words: (1, 3) chars: (2, 5) 
 
---------------------------------------------------------------- 
----------------------------------------------------------------

Fitting vectorizer and preparing training and test data
No. of features: 133727
No. of features after reduction: 26745 

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.5  0.5]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 7.0 / 600 ( 1.16666666667 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.50588551  0.49411449]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 8.0 / 600 ( 1.33333333333 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.50698031  0.49301969]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 9.0 / 600 ( 1.5 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.50750435  0.49249565]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 9.0 / 600 ( 1.5 %)

Returning final model after 4 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       600
        1.0       0.99      0.99      0.99       600

avg / total       0.99      0.99      0.99      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.45  0.55]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 32.0 / 660 ( 4.84848484848 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.47670573  0.52329427]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 36.0 / 660 ( 5.45454545455 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.47998198  0.52001802]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 38.0 / 660 ( 5.75757575758 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.48155733  0.51844267]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 39.0 / 660 ( 5.90909090909 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.48265587  0.51734413]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 41.0 / 660 ( 6.21212121212 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.48423434  0.51576566]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 43.0 / 660 ( 6.51515151515 %)

Iteration # 7
Building new model using probabilistic labels
Class distribution: [ 0.48551415  0.51448585]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 43.0 / 660 ( 6.51515151515 %)

Returning final model after 7 iterations
Threshold given noise level: 1.17573964402e-23
Unlabelled docs below threshold: 523 of 600 


Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.53428317  0.46571683]
Computing attribute probabilities for 26745 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.53930721  0.46069279]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 50.0 / 600 ( 8.33333333333 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.54132577  0.45867423]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 50.0 / 600 ( 8.33333333333 %)

Delta_i: 0
Returning final model after 2 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.92      0.95       600
        1.0       0.92      0.99      0.95       600

avg / total       0.96      0.95      0.95      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.4  0.6]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 54.0 / 720 ( 7.5 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.4453002  0.5546998]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 64.0 / 720 ( 8.88888888889 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.4533052  0.5466948]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 66.0 / 720 ( 9.16666666667 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.45545594  0.54454406]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 68.0 / 720 ( 9.44444444444 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.4573436  0.5426564]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 71.0 / 720 ( 9.86111111111 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.45954677  0.54045323]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 72.0 / 720 ( 10.0 %)

Iteration # 7
Building new model using probabilistic labels
Class distribution: [ 0.46000596  0.53999404]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 72.0 / 720 ( 10.0 %)

Returning final model after 7 iterations
Threshold given noise level: 1.0637203629e-20
Unlabelled docs below threshold: 528 of 600 


Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.53191489  0.46808511]
Computing attribute probabilities for 26745 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.53863427  0.46136573]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 48.0 / 600 ( 8.0 %)

Returning final model after 1 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.92      0.95       600
        1.0       0.93      0.99      0.96       600

avg / total       0.96      0.95      0.95      1200

Determining RN using Rocchio method

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 536 ( 89.33333333333333 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 544
Iterative SVM converged. Reliable negative examples: 544
Ratio of positive examples misclassified as negative by initial SVM: 0.015
Ratio of positive examples misclassified as negative by final SVM: 0.015
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.98      0.91      0.94       600
        1.0       0.91      0.98      0.95       600

avg / total       0.95      0.95      0.95      1200

Determining RN using Cosine Similarity threshold and Rocchio

Computing ranking (cosine similarity to mean positive example)
Choosing Potential Negative examples with ranking threshold
Threshold given noise level: 0.115468445974
Unlabelled docs below threshold: 254 of 600 

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 345 ( 57.5 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 399
Iteration # 2
Reliable negative examples: 433
Iteration # 3
Reliable negative examples: 452
Iteration # 4
Reliable negative examples: 467
Iteration # 5
Reliable negative examples: 474
Iteration # 6
Reliable negative examples: 477
Iteration # 7
Reliable negative examples: 480
Iteration # 8
Reliable negative examples: 483
Iteration # 9
Reliable negative examples: 484
Iterative SVM converged. Reliable negative examples: 484
Ratio of positive examples misclassified as negative by initial SVM: 0.0116666666667
Ratio of positive examples misclassified as negative by final SVM: 0.0166666666667
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.98      0.81      0.88       600
        1.0       0.84      0.98      0.90       600

avg / total       0.91      0.90      0.89      1200

Determining RN using Cosine Similarity threshold and Rocchio

Computing ranking (cosine similarity to mean positive example)
Choosing Potential Negative examples with ranking threshold
Threshold given noise level: 0.129966481771
Unlabelled docs below threshold: 313 of 600 

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 397 ( 66.16666666666667 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 444
Iteration # 2
Reliable negative examples: 464
Iteration # 3
Reliable negative examples: 478
Iteration # 4
Reliable negative examples: 491
Iteration # 5
Reliable negative examples: 498
Iteration # 6
Reliable negative examples: 504
Iteration # 7
Reliable negative examples: 507
Iteration # 8
Reliable negative examples: 508
Iterative SVM converged. Reliable negative examples: 508
Ratio of positive examples misclassified as negative by initial SVM: 0.01
Ratio of positive examples misclassified as negative by final SVM: 0.0133333333333
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.98      0.85      0.91       600
        1.0       0.87      0.99      0.92       600

avg / total       0.92      0.92      0.92      1200

Determining RN using Rocchio method

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 536 ( 89.33333333333333 %)

Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.52816901  0.47183099]
Computing attribute probabilities for 26745 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.52985011  0.47014989]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 36.0 / 600 ( 6.0 %)

Returning final model after 1 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.94      0.96       600
        1.0       0.94      0.99      0.97       600

avg / total       0.97      0.96      0.96      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.45  0.55]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 29.0 / 660 ( 4.39393939394 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.47443142  0.52556858]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 33.0 / 660 ( 5.0 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.47747359  0.52252641]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 35.0 / 660 ( 5.30303030303 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.479141  0.520859]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 36.0 / 660 ( 5.45454545455 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.48014561  0.51985439]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 38.0 / 660 ( 5.75757575758 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.48166781  0.51833219]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 38.0 / 660 ( 5.75757575758 %)

Returning final model after 6 iterations
Threshold given noise level: 4.18774487127e-22
Unlabelled docs below threshold: 526 of 600 


Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 549
Iteration # 2
Reliable negative examples: 551
Iterative SVM converged. Reliable negative examples: 551
Ratio of positive examples misclassified as negative by initial SVM: 0.0166666666667
Ratio of positive examples misclassified as negative by final SVM: 0.015
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.98      0.92      0.95       600
        1.0       0.92      0.98      0.95       600

avg / total       0.95      0.95      0.95      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.4  0.6]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 59.0 / 720 ( 8.19444444444 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.44907763  0.55092237]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 68.0 / 720 ( 9.44444444444 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.45699219  0.54300781]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 72.0 / 720 ( 10.0 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.45964328  0.54035672]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 74.0 / 720 ( 10.2777777778 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.46158541  0.53841459]
Computing attribute probabilities for 26745 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 74.0 / 720 ( 10.2777777778 %)

Returning final model after 5 iterations
Threshold given noise level: 5.96195218055e-17
Unlabelled docs below threshold: 551 of 600 


Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 566
Iteration # 2
Reliable negative examples: 568
Iteration # 3
Reliable negative examples: 569
Iterative SVM converged. Reliable negative examples: 569
Ratio of positive examples misclassified as negative by initial SVM: 0.0183333333333
Ratio of positive examples misclassified as negative by final SVM: 0.0166666666667
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.98      0.94      0.96       600
        1.0       0.95      0.98      0.96       600

avg / total       0.96      0.96      0.96      1200

There are 24 parameter combinations to be evaluated.

(1.6615384615384616, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10})
(0, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 10})
(0, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 10})
(0, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 10})
(0, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 10})
(0, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 10})
(1.6284057971014492, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 100})
(1.115705128205128, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 100})
(1.0084033613445378, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 100})
(0, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 100})
(0, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 100})
(0, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 100})
(1.6284057971014492, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 1000})
(1.6035014005602242, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 1000})
(1.6082051282051284, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 1000})
(1.5093380614657208, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 1000})
(1.415686274509804, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 1000})
(1.35375, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 1000})
(1.6284057971014492, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10000})
(1.6284057971014492, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 10000})
(1.6284057971014492, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 10000})
(1.6284057971014492, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 10000})
(1.6426900584795321, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 10000})
(1.6426900584795321, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 10000})

Best model has parameters {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10} and PU-score 1.66153846154
Building final classifier

---------------------------------------------------------------- 
---------------------------------------------------------------- 
words: (1, 3) chars: (2, 6) 
 
---------------------------------------------------------------- 
----------------------------------------------------------------

Fitting vectorizer and preparing training and test data
No. of features: 200519
No. of features after reduction: 40103 

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.5  0.5]
Computing attribute probabilities for 40103 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 6.0 / 600 ( 1.0 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.50500002  0.49499998]
Computing attribute probabilities for 40103 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 6.0 / 600 ( 1.0 %)

Returning final model after 2 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       1.00      0.99      0.99       600
        1.0       0.99      1.00      0.99       600

avg / total       0.99      0.99      0.99      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.45  0.55]
Computing attribute probabilities for 40103 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 29.0 / 660 ( 4.39393939394 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.47409046  0.52590954]
Computing attribute probabilities for 40103 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 31.0 / 660 ( 4.69696969697 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.4754981  0.5245019]
Computing attribute probabilities for 40103 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 32.0 / 660 ( 4.84848484848 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.47649396  0.52350604]
Computing attribute probabilities for 40103 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 32.0 / 660 ( 4.84848484848 %)

Returning final model after 4 iterations
Threshold given noise level: 2.67932880702e-30
Unlabelled docs below threshold: 540 of 600 


Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.52631579  0.47368421]
Computing attribute probabilities for 40103 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.53301971  0.46698029]
Computing attribute probabilities for 40103 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 40.0 / 600 ( 6.66666666667 %)

Returning final model after 1 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       1.00      0.93      0.96       600
        1.0       0.94      1.00      0.97       600

avg / total       0.97      0.96      0.96      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.4  0.6]
Computing attribute probabilities for 40103 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 50.0 / 720 ( 6.94444444444 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.44079085  0.55920915]
Computing attribute probabilities for 40103 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 54.0 / 720 ( 7.5 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.4452042  0.5547958]
Computing attribute probabilities for 40103 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 57.0 / 720 ( 7.91666666667 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.44719002  0.55280998]
Computing attribute probabilities for 40103 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 57.0 / 720 ( 7.91666666667 %)

Returning final model after 4 iterations
Threshold given noise level: 2.77452846047e-23
Unlabelled docs below threshold: 560 of 600 


Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.51724138  0.48275862]
Computing attribute probabilities for 40103 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.52568736  0.47431264]
Computing attribute probabilities for 40103 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 32.0 / 600 ( 5.33333333333 %)

Returning final model after 1 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       1.00      0.95      0.97       600
        1.0       0.95      1.00      0.97       600

avg / total       0.97      0.97      0.97      1200

Determining RN using Rocchio method

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 556 ( 92.66666666666667 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 557
Iteration # 2
Reliable negative examples: 558
Iterative SVM converged. Reliable negative examples: 558
Ratio of positive examples misclassified as negative by initial SVM: 0.00666666666667
Ratio of positive examples misclassified as negative by final SVM: 0.00666666666667
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.93      0.96       600
        1.0       0.93      0.99      0.96       600

avg / total       0.96      0.96      0.96      1200

Determining RN using Cosine Similarity threshold and Rocchio

Computing ranking (cosine similarity to mean positive example)
Choosing Potential Negative examples with ranking threshold
Threshold given noise level: 0.103039336871
Unlabelled docs below threshold: 281 of 600 

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 358 ( 59.666666666666664 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 393
Iteration # 2
Reliable negative examples: 411
Iteration # 3
Reliable negative examples: 425
Iteration # 4
Reliable negative examples: 439
Iteration # 5
Reliable negative examples: 447
Iteration # 6
Reliable negative examples: 456
Iteration # 7
Reliable negative examples: 464
Iteration # 8
Reliable negative examples: 467
Iteration # 9
Reliable negative examples: 469
Iteration # 10
Reliable negative examples: 471
Iteration # 11
Reliable negative examples: 472
Iteration # 12
Reliable negative examples: 473
Iterative SVM converged. Reliable negative examples: 473
Ratio of positive examples misclassified as negative by initial SVM: 0.00666666666667
Ratio of positive examples misclassified as negative by final SVM: 0.005
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.79      0.88       600
        1.0       0.82      0.99      0.90       600

avg / total       0.91      0.89      0.89      1200

Determining RN using Cosine Similarity threshold and Rocchio

Computing ranking (cosine similarity to mean positive example)
Choosing Potential Negative examples with ranking threshold
Threshold given noise level: 0.115083448346
Unlabelled docs below threshold: 356 of 600 

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 417 ( 69.5 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 450
Iteration # 2
Reliable negative examples: 467
Iteration # 3
Reliable negative examples: 474
Iteration # 4
Reliable negative examples: 483
Iteration # 5
Reliable negative examples: 491
Iteration # 6
Reliable negative examples: 497
Iteration # 7
Reliable negative examples: 498
Iterative SVM converged. Reliable negative examples: 498
Ratio of positive examples misclassified as negative by initial SVM: 0.005
Ratio of positive examples misclassified as negative by final SVM: 0.005
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.83      0.90       600
        1.0       0.85      0.99      0.92       600

avg / total       0.92      0.91      0.91      1200

Determining RN using Rocchio method

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 556 ( 92.66666666666667 %)

Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.51903114  0.48096886]
Computing attribute probabilities for 40103 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.52584749  0.47415251]
Computing attribute probabilities for 40103 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 33.0 / 600 ( 5.5 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.52748989  0.47251011]
Computing attribute probabilities for 40103 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 33.0 / 600 ( 5.5 %)

Delta_i: 0
Returning final model after 2 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       1.00      0.94      0.97       600
        1.0       0.95      1.00      0.97       600

avg / total       0.97      0.97      0.97      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.45  0.55]
Computing attribute probabilities for 40103 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 33.0 / 660 ( 5.0 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.47798775  0.52201225]
Computing attribute probabilities for 40103 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 37.0 / 660 ( 5.60606060606 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.48107796  0.51892204]
Computing attribute probabilities for 40103 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 39.0 / 660 ( 5.90909090909 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.48249971  0.51750029]
Computing attribute probabilities for 40103 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 39.0 / 660 ( 5.90909090909 %)

Returning final model after 4 iterations
Threshold given noise level: 2.72371621209e-37
Unlabelled docs below threshold: 514 of 600 


Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 544
Iteration # 2
Reliable negative examples: 548
Iteration # 3
Reliable negative examples: 549
Iterative SVM converged. Reliable negative examples: 549
Ratio of positive examples misclassified as negative by initial SVM: 0.00333333333333
Ratio of positive examples misclassified as negative by final SVM: 0.005
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.91      0.95       600
        1.0       0.92      0.99      0.96       600

avg / total       0.96      0.95      0.95      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.4  0.6]
Computing attribute probabilities for 40103 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 53.0 / 720 ( 7.36111111111 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.44397769  0.55602231]
Computing attribute probabilities for 40103 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 57.0 / 720 ( 7.91666666667 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.44749786  0.55250214]
Computing attribute probabilities for 40103 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 59.0 / 720 ( 8.19444444444 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.44885218  0.55114782]
Computing attribute probabilities for 40103 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 59.0 / 720 ( 8.19444444444 %)

Returning final model after 4 iterations
Threshold given noise level: 5.81002096015e-26
Unlabelled docs below threshold: 552 of 600 


Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 568
Iteration # 2
Reliable negative examples: 571
Iteration # 3
Reliable negative examples: 572
Iterative SVM converged. Reliable negative examples: 572
Ratio of positive examples misclassified as negative by initial SVM: 0.005
Ratio of positive examples misclassified as negative by final SVM: 0.00666666666667
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       600
        1.0       0.96      0.99      0.97       600

avg / total       0.97      0.97      0.97      1200

There are 24 parameter combinations to be evaluated.

(1.5605555555555555, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10})
(0, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 10})
(0, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 10})
(0, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 10})
(0, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 10})
(0, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 10})
(1.5736694677871148, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 100})
(1.1980541455160745, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 100})
(1.00418410041841, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 100})
(0, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 100})
(0, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 100})
(0, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 100})
(1.5736694677871148, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 1000})
(1.5605555555555555, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 1000})
(1.5804878048780491, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 1000})
(1.5591863517060367, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 1000})
(1.488847117794486, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 1000})
(1.461352657004831, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 1000})
(1.5736694677871148, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10000})
(1.5736694677871148, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 10000})
(1.5736694677871148, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 10000})
(1.5736694677871148, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 10000})
(1.5736694677871148, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 10000})
(1.5736694677871148, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 10000})

Best model has parameters {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 1000} and PU-score 1.58048780488
Building final classifier

---------------------------------------------------------------- 
---------------------------------------------------------------- 
words: (1, 4) chars: (2, 4) 
 
---------------------------------------------------------------- 
----------------------------------------------------------------

Fitting vectorizer and preparing training and test data
No. of features: 108989
No. of features after reduction: 21797 

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.5  0.5]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 6.0 / 600 ( 1.0 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.50515531  0.49484469]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 7.0 / 600 ( 1.16666666667 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.50600512  0.49399488]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 9.0 / 600 ( 1.5 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.50746274  0.49253726]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 10.0 / 600 ( 1.66666666667 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.5081224  0.4918776]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 11.0 / 600 ( 1.83333333333 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.50919589  0.49080411]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 11.0 / 600 ( 1.83333333333 %)

Returning final model after 6 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       600
        1.0       0.98      0.99      0.99       600

avg / total       0.99      0.99      0.99      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.45  0.55]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 31.0 / 660 ( 4.69696969697 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.47489622  0.52510378]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 37.0 / 660 ( 5.60606060606 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.48104378  0.51895622]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 42.0 / 660 ( 6.36363636364 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.48482748  0.51517252]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 43.0 / 660 ( 6.51515151515 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.48604852  0.51395148]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 45.0 / 660 ( 6.81818181818 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.48720791  0.51279209]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 45.0 / 660 ( 6.81818181818 %)

Returning final model after 6 iterations
Threshold given noise level: 2.0273336029e-26
Unlabelled docs below threshold: 425 of 600 


Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.58536585  0.41463415]
Computing attribute probabilities for 21797 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.55980378  0.44019622]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 71.0 / 600 ( 11.8333333333 %)

Returning final model after 1 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       1.00      0.88      0.94       600
        1.0       0.89      1.00      0.94       600

avg / total       0.95      0.94      0.94      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.4  0.6]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 60.0 / 720 ( 8.33333333333 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.44847098  0.55152902]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 65.0 / 720 ( 9.02777777778 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.45400519  0.54599481]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 69.0 / 720 ( 9.58333333333 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.45745971  0.54254029]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 71.0 / 720 ( 9.86111111111 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.45922657  0.54077343]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 72.0 / 720 ( 10.0 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.46001945  0.53998055]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 72.0 / 720 ( 10.0 %)

Returning final model after 6 iterations
Threshold given noise level: 8.07755619823e-21
Unlabelled docs below threshold: 490 of 600 


Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.55045872  0.44954128]
Computing attribute probabilities for 21797 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.54521907  0.45478093]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 54.0 / 600 ( 9.0 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.5453121  0.4546879]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 54.0 / 600 ( 9.0 %)

Delta_i: 0
Returning final model after 2 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       1.00      0.91      0.95       600
        1.0       0.92      1.00      0.96       600

avg / total       0.96      0.95      0.95      1200

Determining RN using Rocchio method

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 530 ( 88.33333333333333 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 541
Iterative SVM converged. Reliable negative examples: 541
Ratio of positive examples misclassified as negative by initial SVM: 0.0283333333333
Ratio of positive examples misclassified as negative by final SVM: 0.0283333333333
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.97      0.90      0.93       600
        1.0       0.91      0.97      0.94       600

avg / total       0.94      0.94      0.94      1200

Determining RN using Cosine Similarity threshold and Rocchio

Computing ranking (cosine similarity to mean positive example)
Choosing Potential Negative examples with ranking threshold
Threshold given noise level: 0.132177828501
Unlabelled docs below threshold: 192 of 600 

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 273 ( 45.5 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 347
Iteration # 2
Reliable negative examples: 420
Iteration # 3
Reliable negative examples: 454
Iteration # 4
Reliable negative examples: 466
Iteration # 5
Reliable negative examples: 472
Iteration # 6
Reliable negative examples: 476
Iteration # 7
Reliable negative examples: 478
Iteration # 8
Reliable negative examples: 480
Iteration # 9
Reliable negative examples: 481
Iteration # 10
Reliable negative examples: 482
Iteration # 11
Reliable negative examples: 484
Iteration # 12
Reliable negative examples: 485
Iterative SVM converged. Reliable negative examples: 485
Ratio of positive examples misclassified as negative by initial SVM: 0.00333333333333
Ratio of positive examples misclassified as negative by final SVM: 0.0283333333333
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.97      0.81      0.88       600
        1.0       0.84      0.97      0.90       600

avg / total       0.90      0.89      0.89      1200

Determining RN using Cosine Similarity threshold and Rocchio

Computing ranking (cosine similarity to mean positive example)
Choosing Potential Negative examples with ranking threshold
Threshold given noise level: 0.161683707507
Unlabelled docs below threshold: 277 of 600 

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 367 ( 61.166666666666664 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 445
Iteration # 2
Reliable negative examples: 474
Iteration # 3
Reliable negative examples: 486
Iteration # 4
Reliable negative examples: 492
Iteration # 5
Reliable negative examples: 495
Iteration # 6
Reliable negative examples: 498
Iterative SVM converged. Reliable negative examples: 498
Ratio of positive examples misclassified as negative by initial SVM: 0.00833333333333
Ratio of positive examples misclassified as negative by final SVM: 0.0283333333333
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.97      0.83      0.89       600
        1.0       0.85      0.97      0.91       600

avg / total       0.91      0.90      0.90      1200

Determining RN using Rocchio method

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 530 ( 88.33333333333333 %)

Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.53097345  0.46902655]
Computing attribute probabilities for 21797 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.53236186  0.46763814]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 40.0 / 600 ( 6.66666666667 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.53297888  0.46702112]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 40.0 / 600 ( 6.66666666667 %)

Delta_i: 0
Returning final model after 2 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.93      0.96       600
        1.0       0.94      0.99      0.97       600

avg / total       0.97      0.96      0.96      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.45  0.55]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 38.0 / 660 ( 5.75757575758 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.48055001  0.51944999]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 40.0 / 660 ( 6.06060606061 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.48381588  0.51618412]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 42.0 / 660 ( 6.36363636364 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.48553203  0.51446797]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 45.0 / 660 ( 6.81818181818 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.48725917  0.51274083]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 45.0 / 660 ( 6.81818181818 %)

Returning final model after 5 iterations
Threshold given noise level: 4.00821291575e-25
Unlabelled docs below threshold: 446 of 600 


Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 518
Iteration # 2
Reliable negative examples: 531
Iteration # 3
Reliable negative examples: 534
Iterative SVM converged. Reliable negative examples: 534
Ratio of positive examples misclassified as negative by initial SVM: 0.0183333333333
Ratio of positive examples misclassified as negative by final SVM: 0.0266666666667
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.97      0.89      0.93       600
        1.0       0.90      0.97      0.93       600

avg / total       0.93      0.93      0.93      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.4  0.6]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 58.0 / 720 ( 8.05555555556 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.44883917  0.55116083]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 70.0 / 720 ( 9.72222222222 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.45896084  0.54103916]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 76.0 / 720 ( 10.5555555556 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.46328646  0.53671354]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 78.0 / 720 ( 10.8333333333 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.46480873  0.53519127]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 80.0 / 720 ( 11.1111111111 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.46631235  0.53368765]
Computing attribute probabilities for 21797 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 80.0 / 720 ( 11.1111111111 %)

Returning final model after 6 iterations
Threshold given noise level: 1.10089914345e-15
Unlabelled docs below threshold: 532 of 600 


Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 557
Iteration # 2
Reliable negative examples: 558
Iterative SVM converged. Reliable negative examples: 558
Ratio of positive examples misclassified as negative by initial SVM: 0.025
Ratio of positive examples misclassified as negative by final SVM: 0.0283333333333
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.97      0.92      0.95       600
        1.0       0.93      0.97      0.95       600

avg / total       0.95      0.95      0.95      1200

There are 24 parameter combinations to be evaluated.

(1.5677419354838709, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10})
(0, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 10})
(0, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 10})
(0, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 10})
(0, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 10})
(0, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 10})
(1.4898071625344353, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 100})
(1.1009174311926606, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 100})
(0, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 100})
(0, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 100})
(0, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 100})
(0, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 100})
(1.4898071625344353, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 1000})
(1.5428571428571429, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 1000})
(1.5632387706855793, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 1000})
(1.4719354838709675, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 1000})
(1.4150406504065038, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 1000})
(1.3813492063492063, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 1000})
(1.4898071625344353, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10000})
(1.4898071625344353, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 10000})
(1.4898071625344353, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 10000})
(1.4898071625344353, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 10000})
(1.4898071625344353, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 10000})
(1.4898071625344353, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 10000})

Best model has parameters {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10} and PU-score 1.56774193548
Building final classifier

---------------------------------------------------------------- 
---------------------------------------------------------------- 
words: (1, 4) chars: (2, 5) 
 
---------------------------------------------------------------- 
----------------------------------------------------------------

Fitting vectorizer and preparing training and test data
No. of features: 157067
No. of features after reduction: 31414 

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.5  0.5]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 10.0 / 600 ( 1.66666666667 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.50811621  0.49188379]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 11.0 / 600 ( 1.83333333333 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.50916818  0.49083182]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 11.0 / 600 ( 1.83333333333 %)

Returning final model after 3 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       600
        1.0       0.98      0.99      0.99       600

avg / total       0.99      0.99      0.99      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.45  0.55]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 35.0 / 660 ( 5.30303030303 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.47923689  0.52076311]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 40.0 / 660 ( 6.06060606061 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.4834342  0.5165658]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 41.0 / 660 ( 6.21212121212 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.48463186  0.51536814]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 42.0 / 660 ( 6.36363636364 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.48528803  0.51471197]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 44.0 / 660 ( 6.66666666667 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.48662645  0.51337355]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 44.0 / 660 ( 6.66666666667 %)

Returning final model after 6 iterations
Threshold given noise level: 1.10007420117e-28
Unlabelled docs below threshold: 512 of 600 


Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.53956835  0.46043165]
Computing attribute probabilities for 31414 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.54118289  0.45881711]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 49.0 / 600 ( 8.16666666667 %)

Returning final model after 1 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.92      0.95       600
        1.0       0.92      0.99      0.96       600

avg / total       0.96      0.95      0.95      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.4  0.6]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 51.0 / 720 ( 7.08333333333 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.44272446  0.55727554]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 62.0 / 720 ( 8.61111111111 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.45080756  0.54919244]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 64.0 / 720 ( 8.88888888889 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.45336651  0.54663349]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 65.0 / 720 ( 9.02777777778 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.4541786  0.5458214]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 65.0 / 720 ( 9.02777777778 %)

Returning final model after 5 iterations
Threshold given noise level: 7.55020520019e-25
Unlabelled docs below threshold: 524 of 600 


Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.53380783  0.46619217]
Computing attribute probabilities for 31414 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.53598463  0.46401537]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 43.0 / 600 ( 7.16666666667 %)

Returning final model after 1 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.93      0.96       600
        1.0       0.93      0.99      0.96       600

avg / total       0.96      0.96      0.96      1200

Determining RN using Rocchio method

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 535 ( 89.16666666666667 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 541
Iteration # 2
Reliable negative examples: 542
Iterative SVM converged. Reliable negative examples: 542
Ratio of positive examples misclassified as negative by initial SVM: 0.02
Ratio of positive examples misclassified as negative by final SVM: 0.02
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.98      0.90      0.94       600
        1.0       0.91      0.98      0.94       600

avg / total       0.94      0.94      0.94      1200

Determining RN using Cosine Similarity threshold and Rocchio

Computing ranking (cosine similarity to mean positive example)
Choosing Potential Negative examples with ranking threshold
Threshold given noise level: 0.115576564735
Unlabelled docs below threshold: 234 of 600 

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 329 ( 54.833333333333336 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 399
Iteration # 2
Reliable negative examples: 446
Iteration # 3
Reliable negative examples: 464
Iteration # 4
Reliable negative examples: 475
Iteration # 5
Reliable negative examples: 478
Iteration # 6
Reliable negative examples: 481
Iteration # 7
Reliable negative examples: 483
Iteration # 8
Reliable negative examples: 485
Iterative SVM converged. Reliable negative examples: 485
Ratio of positive examples misclassified as negative by initial SVM: 0.00666666666667
Ratio of positive examples misclassified as negative by final SVM: 0.02
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.98      0.81      0.88       600
        1.0       0.84      0.98      0.90       600

avg / total       0.91      0.89      0.89      1200

Determining RN using Cosine Similarity threshold and Rocchio

Computing ranking (cosine similarity to mean positive example)
Choosing Potential Negative examples with ranking threshold
Threshold given noise level: 0.13299752284
Unlabelled docs below threshold: 294 of 600 

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 400 ( 66.66666666666667 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 466
Iteration # 2
Reliable negative examples: 490
Iteration # 3
Reliable negative examples: 502
Iteration # 4
Reliable negative examples: 506
Iteration # 5
Reliable negative examples: 508
Iterative SVM converged. Reliable negative examples: 508
Ratio of positive examples misclassified as negative by initial SVM: 0.0116666666667
Ratio of positive examples misclassified as negative by final SVM: 0.0183333333333
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.98      0.85      0.91       600
        1.0       0.86      0.98      0.92       600

avg / total       0.92      0.91      0.91      1200

Determining RN using Rocchio method

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 535 ( 89.16666666666667 %)

Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.52863436  0.47136564]
Computing attribute probabilities for 31414 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.52938114  0.47061886]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 35.0 / 600 ( 5.83333333333 %)

Returning final model after 1 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.94      0.96       600
        1.0       0.94      0.99      0.97       600

avg / total       0.97      0.97      0.97      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.45  0.55]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 34.0 / 660 ( 5.15151515152 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.47959513  0.52040487]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 46.0 / 660 ( 6.9696969697 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.48838329  0.51161671]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 47.0 / 660 ( 7.12121212121 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.48917882  0.51082118]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 47.0 / 660 ( 7.12121212121 %)

Returning final model after 4 iterations
Threshold given noise level: 4.30313048626e-24
Unlabelled docs below threshold: 527 of 600 


Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 551
Iteration # 2
Reliable negative examples: 554
Iterative SVM converged. Reliable negative examples: 554
Ratio of positive examples misclassified as negative by initial SVM: 0.0166666666667
Ratio of positive examples misclassified as negative by final SVM: 0.015
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.98      0.92      0.95       600
        1.0       0.92      0.98      0.95       600

avg / total       0.95      0.95      0.95      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.4  0.6]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 51.0 / 720 ( 7.08333333333 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.44302416  0.55697584]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 64.0 / 720 ( 8.88888888889 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.45336851  0.54663149]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 69.0 / 720 ( 9.58333333333 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.4562857  0.5437143]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 70.0 / 720 ( 9.72222222222 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.45835524  0.54164476]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 71.0 / 720 ( 9.86111111111 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.4592319  0.5407681]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 72.0 / 720 ( 10.0 %)

Iteration # 7
Building new model using probabilistic labels
Class distribution: [ 0.45965669  0.54034331]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 73.0 / 720 ( 10.1388888889 %)

Iteration # 8
Building new model using probabilistic labels
Class distribution: [ 0.46083426  0.53916574]
Computing attribute probabilities for 31414 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 73.0 / 720 ( 10.1388888889 %)

Returning final model after 8 iterations
Threshold given noise level: 5.95658598458e-24
Unlabelled docs below threshold: 530 of 600 


Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 553
Iteration # 2
Reliable negative examples: 557
Iteration # 3
Reliable negative examples: 558
Iterative SVM converged. Reliable negative examples: 558
Ratio of positive examples misclassified as negative by initial SVM: 0.02
Ratio of positive examples misclassified as negative by final SVM: 0.02
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.98      0.92      0.95       600
        1.0       0.93      0.98      0.95       600

avg / total       0.95      0.95      0.95      1200

There are 24 parameter combinations to be evaluated.

(1.5597859327217127, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10})
(0, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 10})
(0, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 10})
(0, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 10})
(0, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 10})
(0, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 10})
(1.5151515151515154, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 100})
(1.0876344086021505, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 100})
(0, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 100})
(0, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 100})
(0, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 100})
(0, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 100})
(1.5151515151515154, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 1000})
(1.5540229885057473, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 1000})
(1.5277777777777775, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 1000})
(1.4635135135135133, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 1000})
(1.3950421940928273, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 1000})
(1.3731755424063115, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 1000})
(1.5151515151515154, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10000})
(1.5151515151515154, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 10000})
(1.5151515151515154, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 10000})
(1.5151515151515154, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 10000})
(1.5151515151515154, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 10000})
(1.5482142857142855, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 10000})

Best model has parameters {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10} and PU-score 1.55978593272
Building final classifier

---------------------------------------------------------------- 
---------------------------------------------------------------- 
words: (1, 4) chars: (2, 6) 
 
---------------------------------------------------------------- 
----------------------------------------------------------------

Fitting vectorizer and preparing training and test data
No. of features: 223859
No. of features after reduction: 44810 

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.5  0.5]
Computing attribute probabilities for 44810 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 7.0 / 600 ( 1.16666666667 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.50591801  0.49408199]
Computing attribute probabilities for 44810 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 9.0 / 600 ( 1.5 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.50731693  0.49268307]
Computing attribute probabilities for 44810 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 9.0 / 600 ( 1.5 %)

Returning final model after 3 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       600
        1.0       0.99      0.99      0.99       600

avg / total       0.99      0.99      0.99      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.45  0.55]
Computing attribute probabilities for 44810 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 29.0 / 660 ( 4.39393939394 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.47464732  0.52535268]
Computing attribute probabilities for 44810 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 33.0 / 660 ( 5.0 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.47747101  0.52252899]
Computing attribute probabilities for 44810 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 34.0 / 660 ( 5.15151515152 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.4783396  0.5216604]
Computing attribute probabilities for 44810 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 34.0 / 660 ( 5.15151515152 %)

Returning final model after 4 iterations
Threshold given noise level: 3.35138444063e-41
Unlabelled docs below threshold: 503 of 600 


Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.54397099  0.45602901]
Computing attribute probabilities for 44810 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.53855784  0.46144216]
Computing attribute probabilities for 44810 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 47.0 / 600 ( 7.83333333333 %)

Returning final model after 1 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.92      0.96       600
        1.0       0.93      0.99      0.96       600

avg / total       0.96      0.96      0.96      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.4  0.6]
Computing attribute probabilities for 44810 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 60.0 / 720 ( 8.33333333333 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.4496653  0.5503347]
Computing attribute probabilities for 44810 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 65.0 / 720 ( 9.02777777778 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.4543611  0.5456389]
Computing attribute probabilities for 44810 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 68.0 / 720 ( 9.44444444444 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.45666806  0.54333194]
Computing attribute probabilities for 44810 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 69.0 / 720 ( 9.58333333333 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.45742194  0.54257806]
Computing attribute probabilities for 44810 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 70.0 / 720 ( 9.72222222222 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.45838407  0.54161593]
Computing attribute probabilities for 44810 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 71.0 / 720 ( 9.86111111111 %)

Iteration # 7
Building new model using probabilistic labels
Class distribution: [ 0.45918069  0.54081931]
Computing attribute probabilities for 44810 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 71.0 / 720 ( 9.86111111111 %)

Returning final model after 7 iterations
Threshold given noise level: 6.66853187705e-30
Unlabelled docs below threshold: 543 of 600 


Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.52493438  0.47506562]
Computing attribute probabilities for 44810 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.52963298  0.47036702]
Computing attribute probabilities for 44810 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 36.0 / 600 ( 6.0 %)

Returning final model after 1 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.94      0.96       600
        1.0       0.94      0.99      0.97       600

avg / total       0.97      0.97      0.97      1200

Determining RN using Rocchio method

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 552 ( 92.0 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 556
Iteration # 2
Reliable negative examples: 558
Iterative SVM converged. Reliable negative examples: 558
Ratio of positive examples misclassified as negative by initial SVM: 0.01
Ratio of positive examples misclassified as negative by final SVM: 0.0116666666667
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.93      0.96       600
        1.0       0.93      0.99      0.96       600

avg / total       0.96      0.96      0.96      1200

Determining RN using Cosine Similarity threshold and Rocchio

Computing ranking (cosine similarity to mean positive example)
Choosing Potential Negative examples with ranking threshold
Threshold given noise level: 0.10312163104
Unlabelled docs below threshold: 286 of 600 

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 373 ( 62.166666666666664 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 424
Iteration # 2
Reliable negative examples: 451
Iteration # 3
Reliable negative examples: 465
Iteration # 4
Reliable negative examples: 474
Iteration # 5
Reliable negative examples: 480
Iteration # 6
Reliable negative examples: 482
Iteration # 7
Reliable negative examples: 483
Iteration # 8
Reliable negative examples: 484
Iteration # 9
Reliable negative examples: 485
Iteration # 10
Reliable negative examples: 486
Iterative SVM converged. Reliable negative examples: 486
Ratio of positive examples misclassified as negative by initial SVM: 0.005
Ratio of positive examples misclassified as negative by final SVM: 0.0133333333333
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.98      0.81      0.89       600
        1.0       0.84      0.99      0.91       600

avg / total       0.91      0.90      0.90      1200

Determining RN using Cosine Similarity threshold and Rocchio

Computing ranking (cosine similarity to mean positive example)
Choosing Potential Negative examples with ranking threshold
Threshold given noise level: 0.115802704189
Unlabelled docs below threshold: 347 of 600 

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 430 ( 71.66666666666667 %)

Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 476
Iteration # 2
Reliable negative examples: 499
Iteration # 3
Reliable negative examples: 509
Iteration # 4
Reliable negative examples: 516
Iteration # 5
Reliable negative examples: 518
Iteration # 6
Reliable negative examples: 519
Iteration # 7
Reliable negative examples: 520
Iterative SVM converged. Reliable negative examples: 520
Ratio of positive examples misclassified as negative by initial SVM: 0.00666666666667
Ratio of positive examples misclassified as negative by final SVM: 0.01
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.87      0.92       600
        1.0       0.88      0.99      0.93       600

avg / total       0.93      0.93      0.93      1200

Determining RN using Rocchio method

Building Rocchio model to determine Reliable Negative examples
Reliable Negative examples in U: 552 ( 92.0 %)

Iterating I-EM with P, U-RN, and RN

Building classifier from Positive and Reliable Negative set
Class distribution: [ 0.52083333  0.47916667]
Computing attribute probabilities for 44810 attributes

Calculating initial probabilistic labels for Reliable Negative and Unlabelled set

Iterating EM algorithm on P, RN and U

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.52528998  0.47471002]
Computing attribute probabilities for 44810 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 32.0 / 600 ( 5.33333333333 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.52666442  0.47333558]
Computing attribute probabilities for 44810 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 32.0 / 600 ( 5.33333333333 %)

Delta_i: 0
Returning final model after 2 iterations
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       600
        1.0       0.95      0.99      0.97       600

avg / total       0.97      0.97      0.97      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.45  0.55]
Computing attribute probabilities for 44810 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 29.0 / 660 ( 4.39393939394 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.47392447  0.52607553]
Computing attribute probabilities for 44810 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 33.0 / 660 ( 5.0 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.47780211  0.52219789]
Computing attribute probabilities for 44810 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 37.0 / 660 ( 5.60606060606 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.48083426  0.51916574]
Computing attribute probabilities for 44810 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 37.0 / 660 ( 5.60606060606 %)

Returning final model after 4 iterations
Threshold given noise level: 1.7763315382e-39
Unlabelled docs below threshold: 510 of 600 


Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 546
Iteration # 2
Reliable negative examples: 554
Iterative SVM converged. Reliable negative examples: 554
Ratio of positive examples misclassified as negative by initial SVM: 0.0116666666667
Ratio of positive examples misclassified as negative by final SVM: 0.0116666666667
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.99      0.92      0.95       600
        1.0       0.93      0.99      0.96       600

avg / total       0.96      0.95      0.95      1200

Determining confidence threshold using Spy Documents and I-EM

Iteration # 1
Building new model using probabilistic labels
Class distribution: [ 0.4  0.6]
Computing attribute probabilities for 44810 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 41.0 / 720 ( 5.69444444444 %)

Iteration # 2
Building new model using probabilistic labels
Class distribution: [ 0.43413975  0.56586025]
Computing attribute probabilities for 44810 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 47.0 / 720 ( 6.52777777778 %)

Iteration # 3
Building new model using probabilistic labels
Class distribution: [ 0.43918632  0.56081368]
Computing attribute probabilities for 44810 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 50.0 / 720 ( 6.94444444444 %)

Iteration # 4
Building new model using probabilistic labels
Class distribution: [ 0.44169162  0.55830838]
Computing attribute probabilities for 44810 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 51.0 / 720 ( 7.08333333333 %)

Iteration # 5
Building new model using probabilistic labels
Class distribution: [ 0.4425534  0.5574466]
Computing attribute probabilities for 44810 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 52.0 / 720 ( 7.22222222222 %)

Iteration # 6
Building new model using probabilistic labels
Class distribution: [ 0.44332806  0.55667194]
Computing attribute probabilities for 44810 attributes
Predicting probabilities for U
Unlabelled instances classified as positive: 52.0 / 720 ( 7.22222222222 %)

Returning final model after 6 iterations
Threshold given noise level: 1.57215664011e-35
Unlabelled docs below threshold: 521 of 600 


Iterating SVM with P, U-RN, and RN
Building initial SVM classifier with Positive and Reliable Negative docs
Predicting U with initial SVM, adding negatively classified docs to RN for iteration
Iteration # 1
Reliable negative examples: 549
Iteration # 2
Reliable negative examples: 553
Iteration # 3
Reliable negative examples: 556
Iterative SVM converged. Reliable negative examples: 556
Ratio of positive examples misclassified as negative by initial SVM: 0.0116666666667
Ratio of positive examples misclassified as negative by final SVM: 0.015
Returning final classifier
Classification Report (on training, not on test data!):

             precision    recall  f1-score   support

        0.0       0.98      0.92      0.95       600
        1.0       0.93      0.98      0.96       600

avg / total       0.96      0.95      0.95      1200

There are 24 parameter combinations to be evaluated.

(1.5677419354838709, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10})
(0, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 10})
(0, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 10})
(0, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 10})
(0, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 10})
(0, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 10})
(1.5677419354838709, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 100})
(1.0926697530864198, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 100})
(0, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 100})
(0, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 100})
(0, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 100})
(0, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 100})
(1.5677419354838709, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 1000})
(1.5796153846153849, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 1000})
(1.5682983682983682, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 1000})
(1.5109271523178807, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 1000})
(1.4595387840670859, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 1000})
(1.4217871485943776, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 1000})
(1.5677419354838709, {'C_pos': 0.5, 'C_neg': 0.5, 'C': 10000})
(1.5677419354838709, {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 10000})
(1.5677419354838709, {'C_pos': 0.9975124378109452, 'C_neg': 0.0024875621890547263, 'C': 10000})
(1.5677419354838709, {'C_pos': 0.9983388704318937, 'C_neg': 0.0016611295681063123, 'C': 10000})
(1.5677419354838709, {'C_pos': 0.9987531172069826, 'C_neg': 0.0012468827930174563, 'C': 10000})
(1.5677419354838709, {'C_pos': 0.999001996007984, 'C_neg': 0.000998003992015968, 'C': 10000})

Best model has parameters {'C_pos': 0.995049504950495, 'C_neg': 0.0049504950495049506, 'C': 1000} and PU-score 1.57961538462
Building final classifier
saving all models to disk
